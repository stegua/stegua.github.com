<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Integer Programming | Spaghetti Optimization]]></title>
  <link href="http://stegua.github.io/blog/categories/integer-programming/atom.xml" rel="self"/>
  <link href="http://stegua.github.io/"/>
  <updated>2017-12-28T22:46:06+01:00</updated>
  <id>http://stegua.github.io/</id>
  <author>
    <name><![CDATA[Stefano Gualandi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[The Impact of Preprocessing on the MIPLIB2003]]></title>
    <link href="http://stegua.github.io/blog/2014/03/19/the-impact-of-preprocessing/"/>
    <updated>2014-03-19T22:38:00+01:00</updated>
    <id>http://stegua.github.io/blog/2014/03/19/the-impact-of-preprocessing</id>
    <content type="html"><![CDATA[<p>What do you know about <strong>preprocessing</strong> for <em>Mixed Integer Programming (MIP)</em> problems?</p>

<p>After a nice chat with <a href="http://dk.linkedin.com/in/bojensen">Bo Jensen</a>, CEO, founder, and co-owner (really, he is a Rocket Scientist!) at <a href="http://www.sulumoptimization.com/">Sulum Optimization</a>, I realised that I know barely anything.</p>

<p>By definition, we have that:</p>

<blockquote>
  <p>“Presolving is a way to transform the given problem instance into an equivalent instance that is (hopefully) easier to solve.” (see, chap. 10 in <a href="http://nbn-resolving.de/urn:nbn:de:0297-zib-11129">Tobias Achterberg’s Thesis</a>)</p>
</blockquote>

<p>All I know is that every MIP solver has a <strong>Presolve</strong> parameter, which can take different values.
For instance, <a href="http://www.gurobi.com">Gurobi</a> has three possible values for that parameter (you can find more details on the <a href="http://www.gurobi.com/documentation/5.0/reference-manual/node718#parameter:Presolve">Gurobi online manual</a>):</p>

<ul>
  <li><em>Presolve=0</em>: no presolve at all</li>
  <li><em>Presolve=1</em>: standard presolve </li>
  <li><em>Presolve=2</em>: aggressive presolve: “More aggressive application of presolve takes more time, but can sometimes lead to a significantly tighter model.”</li>
</ul>

<p>However, I can’t tell you the real <strong>impact</strong> of that parameter on the overall solution process of a MIP instance. Thus, here we go: let me write a new post that addresses this basic question!</p>

<h2 id="how-to-measure-the-impact-of-preprocessing">How to measure the Impact of Preprocessing?</h2>
<p>To measure the impact of preprocessing we need four ingredients:</p>

<ol>
  <li>A MIP solver</li>
  <li>A Data set</li>
  <li>Computer power</li>
  <li>A method to <strong>measure</strong> the impact of preprocessing</li>
</ol>

<p>Changing one of the ingredients could give you different results, but, hopefully, the big picture will not change too much.</p>

<p>As a solver, I have selected the current release of Gurobi (i.e., version 5.6.2). For the data set, likely the most critical ingredient, I have used the <a href="http://miplib.zib.de/miplib2003/">MIPLIB2003</a>, basically because I had already all the 60 instances on my server. For running the test I have used an old cluster from the <a href="http://www-dimat.unipv.it">Math Department</a> of University of Pavia.</p>

<p>The <strong>measure of impact</strong> I have decided to use (after considering other alternatives) is quite conservative: the fraction of closed instances as a function of runtime.</p>

<p>During the last weekend, I have collected a bunch of logs for the 60 instances of the MIPLIB2003, and, then, using <a href="http://www.rstudio.com">RStudio</a>, I have draw the following cumulative plot:</p>

<p><img class="center" src="../../../../../../images/preprocessing.png"></p>

<p>The picture is as simple as clear: </p>

<blockquote>
  <p>Preprocessing does always pay-off and permits to solve around 10% more of the instances within the same time limit!</p>
</blockquote>

<p>In this post, I will not discuss additional technical details, but I just want to add two observations:</p>

<ol>
  <li>Standard preprocessing has removed in average 20.3% of nonzero entries of the original model, while aggressive preprocessing has removed 22.5% of nonzero entries, only a few more.</li>
  <li>The average MIP gaps as reported by Gurobi at timeout are: no-presolve = 13.44%, standard = 9.08%, and aggressive = 11.02%.</li>
</ol>

<p>Likely, the aggressive presolve setting has been decided by Gurobi using a different, much larger, and customer-oriented dataset.</p>

<h2 id="open-questions">Open Questions</h2>
<p>Indeed, preprocessing is a very important feature of a modern MIP solver as Gurobi. Investing few seconds before starting the branch-and-bound MIP search can save a significant amount of runtime. However, a more aggressive preprocessing strategy does not seem to payoff, in average, on the MIPLIB2003.</p>

<p>Unfortunately, preprocessing is somehow disregarded from the research community. There are few recent papers dealing with preprocessing (<em>“ehi! if you do have one, please, let me know about it, ok?”</em>).
Most of papers are from the 90s and about Linear Programming, i.e., without integer variables, which mess up everything.</p>

<p>Here a list of basic questions I have in mind:</p>

<ul>
  <li>If cutting planes are used to approximate the convex hull of an Integer Problem, preprocessing for what is used for, really?</li>
  <li>Preprocessing techniques have been designed considering a trade-off between <strong>efficiency</strong> and <strong>efficacy</strong> (see, MWP Savelsbergh, <em>Preprocessing and Probing Techniques for MIP problems</em>, Journal of Computing, vol6(4) 445-454, 1995). With recent progress in software and hardware technologies, can we revise this trade-off in favor of efficacy?</li>
  <li>Preprocessing techniques used for Linear Programming are effective when applied to LP relaxations of Integer Problems?</li>
  <li>Should preprocessing sparsify the coefficient matrix?</li>
  <li>Using the more recent <a href="http://miplib.zib.de/">MIPLIB2010</a> should we expect much different results?</li>
  <li>Which is a better method to measure the impact of preprocessing on a collection of instances?</li>
</ul>

<p>If you want to share your idea, experience, or opinion, with respect to these questions, you could comment below or send me an email.</p>

<p>Now, to conclude, my bonus question:</p>

<blockquote>
  <p>Do you have any new smart idea for improving preprocessing?</p>
</blockquote>

<p>Well, if you had, I guess you would at least write a paper about, but, do not go for a patent, please!</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[An Informal Report from the Combinatorial Optimization Workshop @ Aussois 2014]]></title>
    <link href="http://stegua.github.io/blog/2014/01/13/informal-report-from-cow-at-aussois-2014/"/>
    <updated>2014-01-13T18:30:00+01:00</updated>
    <id>http://stegua.github.io/blog/2014/01/13/informal-report-from-cow-at-aussois-2014</id>
    <content type="html"><![CDATA[<p>It is very hard to report about the <a href="http://www.iasi.cnr.it/aussois/web/home">Combinatorial Optimization Workshop</a> in <a href="http://www.aussois.com/hiver/">Aussois</a>. It was like an “informal” <a href="http://www.or.uni-bonn.de/ipco/">IPCO</a> with <em>Super Heroes researchers</em> in the audience, leaded by <em>Captain Egon</em>, who appears at work in the following photo-tweet:</p>

<blockquote class="twitter-tweet" lang="en"><p>Egon talks intersection cuts at <a href="https://twitter.com/search?q=%23aussois&amp;src=hash">#aussois</a>. Still the man. <a href="http://t.co/7KMcNyJYV0">pic.twitter.com/7KMcNyJYV0</a></p>&mdash; Jeff Linderoth (@JeffLinderoth) <a href="https://twitter.com/JeffLinderoth/statuses/420852308583276544">January 8, 2014</a></blockquote>
<script async="" src="http://stegua.github.io//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>The Captain gave an inspiring talk by questioning the recursive paradigm of cutting planes algorithms. With a very basic example, <a href="http://public.tepper.cmu.edu/facultydirectory/FacultyDirectoryProfile.aspx?id=39">Balas</a> has shown how a non basic vertex (solution) can produce a much deeper cut than a cut generated by an optimal basis. Around this intuition, Balas has presented a very nice <a href="http://link.springer.com/article/10.1007%2Fs10107-011-0483-x">generalization of Intersection Cuts</a>… a new paper enters my “PAPERS-TO-BE-READ” folder.</p>

<p>To stay on the subject of cutting planes, the talk by Marco Molinaro in the first day of the workshop was really nice. He raises the fundamental question on how important are <strong>sparse cuts</strong> versus <strong>dense cuts</strong>. The importance of sparse cuts comes from linear algebra: when solving the simplex it is better to have small determinants in the coefficient matrix of the Linear Programming relaxation in order to avoid numerical issues; sparse cuts implicitly help in keeping small the determinants (intuitively, you have more zeros in the matrix). Dense cuts play the opposite role, but they can be really important to improve the bound of the LP relaxation.
In his talk, Molinaro has shown and proofed, for three particular cases, when sparse cuts are enough, and when they are not. 
Another paper goes on the “PAPERS-TO-BE-READ” folder.</p>

<p>In the same day of Molinaro, it was really inspiring the talk by Sebastian Pokutta, who really gave a completely new (for me) perspective on <strong>Extended Formulations</strong> by using <a href="http://en.wikipedia.org/wiki/Information_theory">Information Theory</a>. Sebastian is the author of a <a href="http://spokutta.wordpress.com/">blog</a>, and I hope he will post about his talk.</p>

<p>Andrea Lodi has discussed about an Optimization problem that arises in Supervised Learning.  For this problem, the COIN-OR solver <a href="http://www.coin-or.org/Couenne/">Couenne</a>, developed by Pietro Belotti, significantly outperforms <a href="http://www-01.ibm.com/software/commerce/optimization/cplex-optimizer/">CPLEX</a>. The issues seem to come from on a number of basic big-M (indicator) constraints. To make a long story short, if you have to solve a hard problem, it does pay off to try different solvers, since there is not a “win-all” solver. </p>

<blockquote>
  <p>Do you have an original new idea for developing solvers? Do not be intimidated by <a href="http://www-01.ibm.com/software/commerce/optimization/cplex-optimizer/">CPLEX</a> or <a href="http://www.gurobi.com/">Gurobi</a> and go for it!</p>
</blockquote>

<p>The presentation by Marco Senatore was brilliant and his work looks very interesting. I have particularly enjoyed the application in Public Transport that he has mentioned at the end of his talk.</p>

<p>I recommend to have a look at the presentation of Stephan Held about the <strong>Reach-aware Steiner Tree Problem</strong>. He has an interesting Steiner tree-like problem with a very important application in chip design. The presentation has impressive pictures of what optimal solutions look like in chip design.</p>

<p>At the end of talk, Stephan announced the <a href="http://dimacs11.cs.princeton.edu/">11th DIMACS challenge on Steiner Tree Problems</a>.</p>

<p>Eduardo Uchoa gave another impressive presentation on recent progresses on the classical <strong>Capacitated Vehicle Routing Problem</strong> (CVRP). He has a very sophisticated branch-and-price-and-cut algorithm, which comes with a very efficient implementation of every possible idea developed for CVRP, plus new ideas on solving efficiently the pricing sub problems (my understanding, but I might be wrong, is that they have a very efficient dominance rule for solving a shortest path sub problem). 
+1 item in the “PAPERS-TO-BE-READ” folder.</p>

<p>The last day of the workshop, I have enjoyed the two talks by Simge Kucukyavuz and Jim Luedtke on <strong>Stochastic Integer Programming</strong>: for me is a completely new topic, but the two presentations were really inspiring.</p>

<p>To conclude, Domenico Salvagnin has shown how far it is possible to go by carefully using MIP technologies such as <strong>cutting planes</strong>, <strong>symmetry handling</strong>, and <strong>problem decomposition</strong>. Unfortunately, it does happen too often that when someone (typically a non OR expert) has a difficult application problem, he writes down a more or less complicated Integer Programming model, tries a solver, sees it takes too much time, and gives up with exact methods. Domenico, by solving the largest unsolved instance for the 3-dimensional assignment problem, has shown that </p>

<blockquote>
  <p>there are potentially no limits for MIP solvers!</p>
</blockquote>

<p>In this post, I have only mentioned a few talks, which somehow overlap with my research interests. However, every talk was really interesting. Fortunately, Francois Margot has strongly encouraged all of the speakers to upload their slides and/or papers, so you can find (almost) all of them on the <a href="http://www.iasi.cnr.it/aussois/web/home/program/year/2014">program web page of the workshop</a>. Visit the website and have a nice reading!</p>

<p>To conclude, let me steal another nice picture from twitter: </p>

<blockquote class="twitter-tweet" lang="en"><p>Goodbye <a href="https://twitter.com/search?q=%23aussois2014&amp;src=hash">#aussois2014</a> <a href="http://t.co/ODupKKmGTZ">pic.twitter.com/ODupKKmGTZ</a></p>&mdash; Matteo Fischetti (@MFischetti) <a href="https://twitter.com/MFischetti/statuses/421642338759618560">January 10, 2014</a></blockquote>
<script async="" src="http://stegua.github.io//platform.twitter.com/widgets.js" charset="utf-8"></script>

]]></content>
  </entry>
  
</feed>
