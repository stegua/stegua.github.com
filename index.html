
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Spaghetti Optimization</title>
  <meta name="author" content="Stefano Gualandi">

  
  <meta name="description" content="Two years ago, I started to study Computational Optimal Transport (OT), and, now, it is time to wrap up informally the main ideas by using an &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://stegua.github.com/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Spaghetti Optimization" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

<!-- IMPORTANT PLEASE READ THIS: Delete the below line if your blog already uses jQuery in some form. Otherwise a conflict might be created and your blog might not work properly. -->
<!-- Use the below line only if your blog doesn't already use jQuery. Please check your head.html and custom/head.html to be sure. -->
<!-- <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.1/jquery.min.js"></script> -->
<!-- Below lines are necessary for Google Feeds API to work properly. Add them to your head.html or custom/head.html files in the _includes directory of your Octopress blog's source folder -->
<!-- <script type="text/javascript" src="https://www.google.com/jsapi"></script>
<script type="text/javascript">google.load("feeds", "1");</script> -->

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-34931940-2']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>



    <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
    <link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
    <link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

    <meta property="og:url" content="http://stegua.github.com/index.html">
<meta property="og:type" content="website" />

<meta property="og:title" content="Spaghetti Optimization">
<meta property="og:description" content="">
 

 

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
   MathJax.Hub.Config({messageStyle: "none"})
   </script>
</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Spaghetti Optimization</a></h1>
  
    <h2>My cookbook about Math, Algorithms, and Programming</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:stegua.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/credits">Credits</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/12/31/wasserstein-distances-an-operations-research-perspective/">An Informal and Biased Tutorial on Kantorovich-Wasserstein Distances</a></h1>
    
    
      <p class="meta">
        








  



  
<time datetime="2018-12-31T13:13:00+01:00" pubdate data-updated="true">Dec 31<span>st</span>, 2018</time>
        
         | <a href="/blog/2018/12/31/wasserstein-distances-an-operations-research-perspective/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Two years ago, I started to study <strong>Computational Optimal Transport (OT)</strong>, and, now, it is time to wrap up informally the main ideas by using an <em>Operations Research (OR)</em> perspective with a <em>Machine Learning (ML)</em> motivation.</p>

<p>Yes, an <a href="https://twitter.com/hashtag/orms">OR</a> perspective.</p>

<blockquote>
  <p>Why an OR perspective?</p>
</blockquote>

<p>Well, because most of the current theoretical works on Optimal Transport have a strong functional analysis bias, and, hence, the are pretty far to be an “easy reading” for anyone working on a different research area. Since I’m more comfortable with “summations” than with “integrations”, in this post I focus only on Discrete Optimal Transport and on Kantorovich-Wasserstein distances between a pair of discrete measures.</p>

<blockquote>
  <p>Why an <a href="https://nips.cc/Conferences/2017/Schedule?showEvent=8758">ML</a> motivation?</p>
</blockquote>

<p>Because measuring the <strong>similarity</strong> between complex objects is a crucial basic step in several <a href="https://twitter.com/hashtag/machinelearning?vertical=news&amp;src=hash">#machinelearning</a> tasks. Mathematically, in order to measure the similarity (or dissimilarity) between two objects we need a metric, i.e., a distance function. And <em>Optimal Transport</em> gives us a powerful similarity measure based on the solution of a <strong>Combinatorial Optimization</strong> problem, which can be formulated and solved with <strong>Linear Programming</strong>.</p>

<p><strong>The main Inspirations for this post are:</strong></p>

<p><em>. My current favorite tutorial is <a href="https://arxiv.org/abs/1801.07745">Optimal Transport on Discrete Domains</a>, by <a href="http://people.csail.mit.edu/jsolomon/">Justin Solomon</a>.
*. Two years ago, I started to study this topic thanks to <a href="https://www-dimat.unipv.it/savare/">Giuseppe Savaré</a>, and I wrote this post by looking also to <a href="https://www-dimat.unipv.it/savare/Ravello2010/ravelloB.pdf">his set of slides</a>. He has several interesting papers and you can look at his <a href="https://www-dimat.unipv.it/savare/pubblicazioni/all.html">publications list</a>.
*. For a complete overview of this topic look at the <a href="https://optimaltransport.github.io/book/">Computational Optimal Transport</a> book, by <a href="http://www.gpeyre.com/">Gabriel Peyré</a> and <a href="http://marcocuturi.net/">Marco Cuturi</a>. These two researchers, together with Justin Solomon, where among the organizers of two <a href="https://en.wikipedia.org/wiki/Conference_on_Neural_Information_Processing_Systems">#NeurIPS</a> workshops, in <a href="http://www.iip.ist.i.kyoto-u.ac.jp/OTML2014/doku.php?id=home">2014</a> and in <a href="http://otml17.marcocuturi.net/">2017</a>, on *Optimal Transport and Machine Learning</em>.
*. For a broader history of Combinatorial Optimization till 1960, see <a href="https://homepages.cwi.nl/~lex/files/histco.pdf">this manuscript by Alexander Schrijver</a>.</p>

<p><strong>DISCLAIMER 1:</strong> This is a long “ongoing” post, and, despite my efforts, it might contain errors of any type. If you have any suggestion for improving this post, please (!), let me know about: I will be more than happy to mention you (or any of your avatars) in the acknowledgement section. Otherwise, if you prefer, I can offer you a drink, whenever we will meet in real life.</p>

<p><strong>DISCLAIMER 2:</strong> I wrote this post while reading the book <strong><a href="https://www.goodreads.com/book/show/9969571-ready-player-one">Ready Player One</a></strong>, by Ernest Cline.</p>

<p><strong>DISCLAIMER 3:</strong> I’m recruiting postdocs. If you like the topic of this post and you are looking for a postdoc position, write me an email.</p>

<h2 id="similarity-measures-and-distance-functions">Similarity measures and distance functions</h2>
<p>A <strong>metric</strong> is a function, usually denoted by <script type="math/tex">d</script>, between a pair of objects belonging to a space <script type="math/tex">X</script>:</p>

<script type="math/tex; mode=display">d : X \times X \rightarrow \mathbb{R}_+</script>

<p>Given any triple of points <script type="math/tex">x,y,z \in X</script>, the conditions that <script type="math/tex">d</script> must satisfy in order to be a metric are:</p>

<ol>
  <li><script type="math/tex">d(x,y) \geq 0</script> <em>(non negativity)</em></li>
  <li><script type="math/tex">d(x,y) = 0 \Leftrightarrow x=y</script> <em>(identity of indiscernibles)</em></li>
  <li><script type="math/tex">d(x,y) = d(y,x)</script> <em>(symmetry)</em></li>
  <li><script type="math/tex">d(x,z) \leq d(x,y) + d(y,z)</script> <em>(triangle inequality or subadditivity)</em></li>
</ol>

<p>If the space <script type="math/tex">X</script> is <script type="math/tex">\mathbb{R}^k</script>, then <script type="math/tex">\mathbf{x}, \mathbf{y}, \mathbf{z}</script> are vectors of <script type="math/tex">k</script> elements, and the most common distance is indeed the Euclidean function</p>

<script type="math/tex; mode=display">d(\mathbf{x},\mathbf{y}) = \sqrt{\sum_{i = 1}^k(x_i - y_i)^2}</script>

<p>where <script type="math/tex">x_i</script> is the <script type="math/tex">i</script>-th component of the vector <script type="math/tex">\mathbf{x}</script>. Clearly, the algorithmic complexity of computing (in finite precision) this distance is linear with the dimension of <script type="math/tex">X</script>.</p>

<p><strong>QUESTION:</strong> What if we want to compute the distance between a pair of clouds of <script type="math/tex">n</script> points defined in <script type="math/tex">\mathbb{R}^k</script>?</p>

<p>If we want to compute the distance between the two vectors, that represent the two clouds of <script type="math/tex">n</script> points, we need to define a distance function.</p>

<p>Let me fix the notation first. If <script type="math/tex">\mathbf{x}</script> is a vector, then <script type="math/tex">x_i</script> is the <script type="math/tex">i</script>-th element. Suppose we have two matrices <script type="math/tex">\mathbf{X}</script> and <script type="math/tex">\mathbf{Y}</script> with <script type="math/tex">n \times k</script> elements, which represent <script type="math/tex">n</script> points in <script type="math/tex">\mathbb{R}^k</script>. We denote by <script type="math/tex">\mathbf{x}_i</script> the <script type="math/tex">i</script>-th row of matrix <script type="math/tex">\mathbf{X}</script>, and by <script type="math/tex">x_{ij}</script> the <script type="math/tex">j</script>-th element of row <script type="math/tex">i</script>. Indeed, the rows <script type="math/tex">\mathbf{x}_i</script> and <script type="math/tex">\mathbf{y}_i</script> of the two matrices give the coordinates <script type="math/tex">x_{i1},\dots,x_{ik}</script> and <script type="math/tex">y_{i1},\dots,y_{ik}</script> of the two corresponding points.</p>

<p>Whenever <script type="math/tex">k=1</script>, a simple choice is to consider the <a href="https://en.wikipedia.org/wiki/Minkowski_distance">Minkowski Distance</a>, which is a metric for normed vector spaces:</p>

<script type="math/tex; mode=display">M_p(\mathbf{x},\mathbf{y}) = \left( \sum_{i=1}^n \mid x_i - y_i\mid^p \right)^{\frac{1}{p}}</script>

<p>where typical values of <script type="math/tex">p</script> are:</p>

<ul>
  <li><script type="math/tex">p=1</script> (Manhattan distance)</li>
  <li><script type="math/tex">p=2</script> (Euclidean distance, see above)</li>
  <li><script type="math/tex">p=\infty</script> (Infinity distance)</li>
</ul>

<p>We have also the Minkowski norm, that is a function</p>

<script type="math/tex; mode=display">\ell_p : \mathbb{R} \rightarrow \mathbb{R}_+</script>

<p>computed as</p>

<script type="math/tex; mode=display">\ell_p(\mathbf{x}) = \left( \sum_{i=1}^n \mid x_i \mid^p\right)^{\frac{1}{p}}</script>

<p>Whenever <script type="math/tex">k>1</script>, we have to consider a more general distance function:</p>

<script type="math/tex; mode=display">D : \mathbb{R}^{n \times k} \times \mathbb{R}^{n \times k} \rightarrow \mathbb{R}_+</script>

<p>such that the relations (1)-(4) are satisfied. We could use as distance function <script type="math/tex">D(\mathbf{X},\mathbf{Y})</script> any <a href="https://en.wikipedia.org/wiki/Matrix_norm">matrix norm</a>, but, to begin with, we can use the Minkowski distance twice in cascade as follows.</p>

<ol>
  <li>First, we compute the distance between a pair of points in <script type="math/tex">\mathbb{R}^k</script>, which we call the <strong>ground distance</strong>, using <script type="math/tex">M_q</script>, with <script type="math/tex">q\geq 1</script>. By applying this function to all the <script type="math/tex">n</script> pairs of points, we get a vector <script type="math/tex">\mathbf{z}</script> of <script type="math/tex">n</script> non-negative values:</li>
</ol>

<script type="math/tex; mode=display"> z_i = M_q(\mathbf{x}_i,\mathbf{y}_i), \quad i=1,\dots, n</script>

<ol>
  <li>Second, we apply the Minkowski norm <script type="math/tex">\ell_p</script> to the vector <script type="math/tex">\mathbf{z}</script>.</li>
</ol>

<p>Composing these two operations, we can define a distance function between a pair of vectors of points (i.e., pair of matrices) as follows:</p>

<script type="math/tex; mode=display">% <![CDATA[
D_{p,q}(\mathbf{X},\mathbf{Y}) = \ell_p(\mathbf{z}) = \ell_p(\left< M_q(\mathbf{x}_i,\mathbf{y}_i)\right>) = \left( \sum_{i=1}^n \left( \sum_{j = 1}^n \left(x_{ij} - y_{ij}\right)^q  \right)^{\frac{p}{q}} \right)^{\frac{1}{p}} %]]></script>

<p>Note that for <script type="math/tex">p=q=2</script>, we get</p>

<script type="math/tex; mode=display">D_{2,2}(\mathbf{X},\mathbf{Y}) = \sqrt{\sum_{i=1}^n \sum_{j = 1}^n \left(x_{ij} - y_{ij}\right)^2} = \mid\mid \mathbf{X} - \mathbf{Y}\mid\mid_F</script>

<p>which is the <a href="https://en.wikipedia.org/wiki/Matrix_norm#Frobenius_norm">Frobenius Norm</a> of the element wise difference <script type="math/tex">\mathbf{X} - \mathbf{Y}</script>.</p>

<p>The main drawback of this distance function is that it implicitly relies on the order (position) of the single points in the two input vectors: any permutation of one (or both) of the two vectors will yield a different value of the ground distance. This happens because the distance function between the two input vectors considers only “interactions” between the <script type="math/tex">i</script>-th pair of points stored at the same <script type="math/tex">i</script>-th position in the two vectors.</p>

<p><strong>IMPORTANT.</strong> Here is where Discrete Optimal Transport comes into action: it offers an alternative distance function based on the solution of a <strong>Combinatorial Optimization</strong> problem, which is, in the simplest case, formulated as the following <strong>Linear Program</strong>:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}\mathcal{W}_d(\mathbf{X},\mathbf{Y}) := \min \;\;& \sum_{i=1}^n\sum_{j=1}^n d(\mathbf{x}_i,\mathbf{y}_j) \pi_{ij} \\
 & \sum_{i=1}^n \pi_{ij} = 1& j=1,\dots,n \\
 & \sum_{j=1}^n \pi_{ij} = 1& i=1,\dots,n \\
 & \pi_{ij} \geq 0 & i=1,\dots,n, j=1,\dots,n .
 \end{aligned} %]]></script>

<p>If you have a minimal <a href="https://twitter.com/hashtag/orms">#orms</a> background at this point you should have recognized that this problem is a standard <a href="https://en.wikipedia.org/wiki/Assignment_problem">Assignment Problem</a>: we have to assign each point of the first vector <script type="math/tex">\mathbf{x}</script> to a single point of the second vector <script type="math/tex">\mathbf{y}</script>, in such a way that the overall cost is minimum. From an optimal solution of this problem, we can select among all possible permutations of the rows of <script type="math/tex">\mathbf{Y}</script>, the permutation that gives the minimal value of the Frobenius norm.</p>

<p>Whenever the ground distance <script type="math/tex">d(\mathbf{x},\mathbf{y})</script> is a metric, then <script type="math/tex">\mathcal{W}_d(\mathbf{X},\mathbf{Y})</script> is a metric as well. In other terms, the optimal value of this problem is a measure of distance between the two vectors, while the optimal values of the decision variables <script type="math/tex">\mathbf{\pi}</script> gives a mapping from the rows of <script type="math/tex">\mathbf{X}</script> to the rows of <script type="math/tex">\mathbf{Y}</script> (in OT terminology, an <em>optimal plan</em>). This is possible because the LP problem has a <a href="https://en.wikipedia.org/wiki/Unimodular_matrix">Totally Unimodular</a> coefficient matrix, and, hence, every basic optimal solution of the LP problem has integer values.</p>

<blockquote>
  <p><strong>WAIT, LET ME STOP HERE FOR A SECOND!</strong></p>
</blockquote>

<p>I am being too technical, too early. Let me take a step back in <em>History</em>.</p>

<h2 id="once-upon-a-time-from-monge-to-kantorovich">Once Upon a Time: from Monge to Kantorovich</h2>
<p>The History of Optimal Transport is quite fascinating and it begins with the <a href="https://gallica.bnf.fr/ark:/12148/bpt6k35800/f796"><em>Mémoire sur la théorie des déblais et des remblais</em></a> by <a href="https://en.wikipedia.org/wiki/Gaspard_Monge">Gaspard Monge</a> (1746-1818). I like to think of Gaspard as visiting the <a href="https://en.wikipedia.org/wiki/Dune_of_Pilat">Dune of Pilat</a>, near Bordeaux, and then writing his <em>Mémoire</em> while going back to home… but this is only my imagination. Still, particles of sand give me the most concrete idea for passing from a continuous to a discrete problem.</p>

<p><img class="center" src="../../../../../../images/dune_pillat.JPG" /></p>

<p>In his <em>Mémoire</em>, Gaspard Monge considered the problem of transporting <em>“des terres d’un lieu dans un autre”</em> at minimal cost. The idea is that we have first to consider the cost of transporting a single molecule of <em>“terre”</em>, which is proportional to its weight and to the distance from its initial and final position. The total cost of transportation is given by summing up the transportation cost of each single molecule. Using the Lex Schrijver’s words, Monge’s transportation problem was <a href="https://homepages.cwi.nl/~lex/files/histco.pdf">camouflaged as a continuous problem</a>.</p>

<p>The idea of Gaspard is to assign to each initial position a single final destination: it is not possible to split a molecule into smaller parts. This unsplittable version of the problem posed a very challenging problem where <a href="https://math.berkeley.edu/~evans/Monge-Kantorovich.survey.pdf"><em>“the direct methods of the calculus of variations fail spectacularly”</em></a> (<a href="https://math.berkeley.edu/~evans/">Lawrence C. Evans</a>, see link at page 5). This challenge stayed unsolved until the work of <a href="https://en.wikipedia.org/wiki/Leonid_Kantorovich">Leonid Kantorovich</a> (1912-1986).</p>

<p>Curiously, Leonid did not arrive to the transportation problem while studying directly the work of Monge. Instead, he was asked to solve an industrial resource allocation problem, which is more general than Monge’s problem. Only a few years later, he reconsidered his contribution in terms of the continuous probabilistic version of Monge’s transportation problem. However, I am unable to state the true technical contributions of Leonid with respect to the work of Gaspard in a short post (well, honestly, I would be unable even in an infinite post), but I recommend you to read the <a href="https://link.springer.com/article/10.1007%2Fs00283-013-9380-x">Long History of the Monge-Kantorovich Transportation Problem</a>.</p>

<p>Anyway, I have pretty clear the two main concepts that are the foundations of the work by Kantorovich:</p>

<ol>
  <li><strong>RELAXATION</strong>: He relaxes the problem posed by Gaspard and he proves that an optimal solution of the relaxation equals an optimal solution of the original problem (Here is the link to the very unofficial soundtrack of his work: <a href="https://www.youtube.com/watch?v=RVmG_d3HKBA">“Relax, take it easy!”</a>). Indeed, Leonid relaxed formulation allows each molecule to be split across several destinations, differently from the formulation of Monge. In OR terms, he solves a Hitchcock Problem, not an Assignment Problem. For more details, see Chapter 1 of the <a href="https://optimaltransport.github.io/book/">Computational Optimal Transport</a>.</li>
</ol>

<p><img class="center" src="../../../../../../images/relax_easy.PNG" /></p>

<ol>
  <li><strong>DUALITY</strong>: Leonid uses a dual formulation of the relaxed problem. Indeed, he <em>invented</em> the dual potential functions and he sketched the first version of dual simplex algorithm. Unfortunately, I studied Linear Programming duality without having an historical perspective, and hence duality looks like <em>obvious</em>, but at the time is was clearly a new concept.</li>
</ol>

<p>For the records, Leonid Kantorovich won the Nobel Prize, and <a href="https://www.nobelprize.org/prizes/economic-sciences/1975/kantorovich/25950-autobiography-1975/">his autobiography</a> merits to be read more than once.</p>

<p>Well, I have still so much to learn from the past!</p>

<h3 id="two-fields-medal-winners-alessio-figalli-and-cedric-villani">Two Fields medal winners: Alessio Figalli and Cedric Villani</h3>
<p>If you think that Optimal Transport belongs to the past, you are wrong!</p>

<p>Last summer (2018), in Rio de Janeiro, <a href="https://people.math.ethz.ch/~afigalli/">Alessio Figalli</a> won the <a href="https://en.wikipedia.org/wiki/Fields_Medal">Fields Medal</a> with this citation:</p>

<blockquote>
  <p><em>“for his contributions to the <strong>theory of optimal transport</strong>, and its application to partial differential equations, metric geometry, and probability”</em></p>
</blockquote>

<p>Alessio is not the first Fields medalist who worked on Optimal Transport. Already <a href="https://cedricvillani.org/for-mathematicians/">Cedric Villani</a>, who wrote the <a href="http://cedricvillani.org/wp-content/uploads/2012/08/B07.StFlour.pdf">most cited book</a> on Optimal Transport [1], won the Fields Medal in 2010. I strongly suggest you to look any of <a href="https://www.youtube.com/watch?v=Kc0Kthyo0hU">his lectures available on Youtube</a>. And … do you know that Villani spent a short period of time during his PhD in my current Math Dept. at University of Pavia?</p>

<p>As an extra bonus, if you don’t know what a Fields Medal is, you can have Robin Williams to explain the prize in this clip taken from <a href="https://www.youtube.com/watch?v=TRU4YYxM7vU">Good Will Hunting</a>.</p>

<h2 id="discrete-optimal-transport-and-linear-programming">Discrete Optimal Transport and Linear Programming</h2>
<p>It is time of being technical again and to move from the Monge assignment problem, to the Kantorovich “relaxed” transportation problem. In the assignment model presented above, we are implicitly considering that all the positions are occupied by a single molecule of unitary weight. If we want to consider the more general setting of Discrete Optimal Transport, we need to consider the “mass” of each molecule, and to formulate the problem of transporting the total mass at minimum cost. Before presenting the model, we define formally the concept of a <strong>discrete measure</strong> and of the <strong>cost matrix</strong> between all pairs of molecule positions.</p>

<p><strong>DISCRETE MEASURES:</strong> Given a of vector of <script type="math/tex">n</script> positions <script type="math/tex">\mathbf{x}_i</script>, and given the <a href="https://en.wikipedia.org/wiki/Dirac_delta_function">Dirac delta function</a>, we can define the <em>Dirac measures</em> <script type="math/tex">\delta_{\mathbf{x}_i}</script> as</p>

<script type="math/tex; mode=display">% <![CDATA[
\delta_{\mathbf{x}_i}(A) = \left\{ \begin{array}{ll} 1 & \text{if} \;\;\mathbf{x}_i \in A \subseteq X \\ 0 & \text{if} \;\;\mathbf{x}_i \notin A \subseteq X \\  \end{array}\right. %]]></script>

<p>Given a vector of <script type="math/tex">n</script> weights <script type="math/tex">\mu_i</script>, one associated to each element of <script type="math/tex">\mathbf{x}</script>, we can define the <strong>discrete measure</strong> <script type="math/tex">\mathbf{\mu}</script> as</p>

<script type="math/tex; mode=display">\mu(A) = \sum_{i=1}^n \mu_i \delta_{\mathbf{x}_i}</script>

<p>Note the <script type="math/tex">\mu</script> is a function of type: <script type="math/tex">\mu : A \rightarrow \mathbb{R}_+</script>, for any subset <script type="math/tex">A</script> of <script type="math/tex">X</script>. The vector <script type="math/tex">\mathbf{x}</script> is called the support of the measure <script type="math/tex">\mathbf{\mu}</script>. In Computer Science terms, <em>a discrete measure is defined by a vector of pairs</em>, where each pair contains a positive number <script type="math/tex">\mu_i</script> (the measured value) and its support point <script type="math/tex">\mathbf{x}_i</script> (the location where the measure occurred). Note that <script type="math/tex">\mathbf{x}_i</script> is a (small?) vector storing the coordinates of the <script type="math/tex">i</script>-th point.</p>

<p><strong>COST MATRIX:</strong> Given two discrete measures <script type="math/tex">\mathbf{\mu}</script> and <script type="math/tex">\mathbf{\nu}</script>, the first with support <script type="math/tex">\mathbf{x}</script> and the second with support <script type="math/tex">\mathbf{y}</script>, we can define the following cost matrix:</p>

<script type="math/tex; mode=display">c_{ij} = d(\mathbf{x}_i, \mathbf{y}_j), \quad \text{for } i=1,\dots,n \text{ and } j= 1,\dots, m</script>

<p>where <script type="math/tex">d</script> is a distance function, such as, for instance, the Minkowski distance <script type="math/tex">M_q(\mathbf{x},\mathbf{y})</script> defined before. Note that <script type="math/tex">\mathbf{\mu}</script> has <script type="math/tex">n</script> elements, and <script type="math/tex">\mathbf{\nu}</script> has <script type="math/tex">m</script> elements.</p>

<h3 id="kantorovich-wasserstein-distances-between-two-discrete-measures">Kantorovich-Wasserstein distances between two discrete measures</h3>
<p>At this point, we have all the basic elements to define the <strong>Kantorovich-Wasserstein distance function between discrete measures</strong> in terms of the solution of a (huge) Linear Program.</p>

<p><strong>INPUT:</strong> Two discrete measures <script type="math/tex">\mathbf{\mu}</script> and <script type="math/tex">\mathbf{\nu}</script> defined on a metric space <script type="math/tex">X</script>, and the corresponding supports <script type="math/tex">\mathbf{x}</script> and <script type="math/tex">\mathbf{y}</script>, having <script type="math/tex">n</script> and <script type="math/tex">m</script> elements, respectively. A distance function <script type="math/tex">d</script>, which permits to compute the cost <script type="math/tex">c_{ij}</script>.</p>

<p><strong>OUTPUT:</strong> A transportation plan <script type="math/tex">\mathbf{\pi}</script> and a value of distance of <script type="math/tex">\mathcal{W}(\mathbf{\mu}, \mathbf{\nu})</script> that corresponds to an optimal solution of the following Linear Program:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\mathcal{W}(\mathbf{\mu},\mathbf{\nu}) := \min \;\;& \sum_{i=1}^n\sum_{j=1}^m c_{ij} \pi_{ij} \\
 & \sum_{j=1}^m \pi_{ij} \geq \mu_i & i=1,\dots,n \\
 & \sum_{i=1}^n \pi_{ij} \leq \nu_j& j=1,\dots,m \\
 & \pi_{ij} \geq 0 & i=1,\dots,n, j=1,\dots,m.
 \end{aligned} %]]></script>

<p>This Linear Program is indeed a special case of the <a href="https://www.jstor.org/stable/2627172?seq=1#page_scan_tab_contents">Transportation Problem</a>, known also as the Hitchcock-Koopmans problem. It is a special case because the cost vector has a strong structure that should be exploited as much as possible.</p>

<p><strong>Computational Challenge:</strong> While the previous problem is polynomially solvable, the size of practical instances is very large. For instance, if you want to compute the distance between a pair of grey scale images of resolution <script type="math/tex">512 \times 512</script> pixels, you end up with an LP with <script type="math/tex">512^4 = 68\;719\;476\;736</script> cost coefficients. Hence, these problems must be handled with care. If you want to see how the solution time and memory requirement scale for grey scale image, please, have a look at the <a href="http://www.iasi.cnr.it/aussois/web/uploads/2018/slides/gualandis.pdf">slides of my talk at Aussois (2018)</a>.</p>

<p><img class="center" src="../../../../../../images/ot_challenge.png" /></p>

<h3 id="kantorovich-wasserstein-distance">KANTOROVICH-WASSERSTEIN DISTANCE</h3>

<p>Whenever</p>

<ol>
  <li>The two measure are discrete probability measures, that is, both <script type="math/tex">\sum_{i=1}^n \mu_i = 1</script> and <script type="math/tex">\sum_{j = 1}^m \nu_j = 1</script> (i.e., <script type="math/tex">\mathbf{\mu}</script> and <script type="math/tex">\mathbf{\nu}</script> belongs to the probability simplex), and,</li>
  <li>The cost vector is defined as the <script type="math/tex">p</script>-th power of a distance,</li>
</ol>

<p>then we define the <strong>Kantorovich-Wasserstein distance of order <script type="math/tex">p</script></strong> as the following functional:</p>

<script type="math/tex; mode=display">\mathcal{W}_p(\mathbf{\mu},\mathbf{\nu}) := \left(\min_{\pi \in U} \sum_{i=1}^n\sum_{j=1}^m d(\mathbf{x}_i, \mathbf{y}_j)^p \pi_{ij} \right)^{\frac{1}{p}}</script>

<p>where the set <script type="math/tex">U</script> is defined as:</p>

<script type="math/tex; mode=display">% <![CDATA[
U := \left\{\begin{array}{ll}
 \sum_{j=1,\dots,m} \pi_{ij} \leq \mu_i & i=1,\dots,n \\
 \sum_{i=1,\dots,n} \pi_{ij} \geq \nu_j& j=1,\dots,m \\
 \pi_{ij} \geq 0 & i=1,\dots,n, j=1,\dots,m. \\
 \end{array}
 \right\}
 %]]></script>

<p>From a mathematical perspective, the most interesting case is the order <script type="math/tex">p=2</script>, which <em>generalizes</em> the Euclidean distance to discrete probability vectors. Note that in this formulation, the two constraint sets defining <script type="math/tex">U</script> could be replaced with equality constraints, since <script type="math/tex">\mathbf{\mu}</script> and <script type="math/tex">\mathbf{\nu}</script> belongs to the probability simplex. In addition, any Combinatorial Optimization algorithm must be used with care, since all the cost and constraint coefficients are not integer.
<strong>Note:</strong> The <script type="math/tex">p</script> power used for the ground distance must not be confused with the order (power) of a Kantorovich-Wasserstein distance.</p>

<h3 id="earth-mover-distance">EARTH MOVER DISTANCE</h3>

<p>A particular case of the Kantorovich-Wasserstein distance very popular in the Computer Vision research community, is the so-called <strong>Earth Mover Distance (EMD)</strong> [2], which is used between a pair of <script type="math/tex">k</script>-dimensional histograms obtained by preprocessing the images of interest. In this case, (i) we have <script type="math/tex">n=m</script>, (ii) we do not require the discrete measures to belong to the probability simplex, and (iii) we do not even require that the two measures are <em>balanced</em>, that is, <script type="math/tex">\sum_{i=1}^n \mu_i = \sum_{j=1}^n \nu_j</script>. In Optimal Transport terminology, the Earth Mover Distance solves an <strong>unbalanced optimal transport problem</strong>. For the EMD, the feasibility set <script type="math/tex">U</script> is replaced by the set:</p>

<script type="math/tex; mode=display">% <![CDATA[
V := \left\{\begin{array}{ll}
 \sum_{i=1}^n \sum_{j=1}^n \pi_{ij} = \min \{ \sum_{i=1}^n \mu_i, \sum_{j=1}^n \nu_j \}& \\
 \sum_{j=1,\dots,n} \pi_{ij} \geq \mu_i & i=1,\dots,n \\
 \sum_{i=1,\dots,n} \pi_{ij} \geq \nu_j& j=1,\dots,n \\
 \pi_{ij} \geq 0 & i=1,\dots,n, j=1,\dots,n. \\
 \end{array}
 \right\}
 %]]></script>

<p>The cost function is taken with the order <script type="math/tex">p=1</script>:</p>

<script type="math/tex; mode=display">EMD(\mathbf{x},\mathbf{y}) := \min_{\pi \in V} \sum_{i=1}^n\sum_{j=1}^m d(x_i, y_j) \pi_{ij}</script>

<p>The most used function <script type="math/tex">d</script> is the Minkowski distance induced by the <script type="math/tex">\ell_p</script> norm.</p>

<h3 id="word-mover-distance">WORD MOVER DISTANCE</h3>

<p>A very interesting application of discrete optimal transport is the definition of a metric for text documents [3]. The main idea is, first, to exploit a <a href="https://en.wikipedia.org/wiki/Word_embedding">word embedding</a> obtained, for instance, with the popular <a href="https://www.tensorflow.org/tutorials/representation/word2vec">word2vec</a> neural network [4], and, second, to formulate the problem of “transporting” a text document into another at minimal cost.</p>

<blockquote>
  <p>Yes, but … how we compute the ground distance between two words?</p>
</blockquote>

<p>A word embedding associates to each word of a given vocabulary a vector of <script type="math/tex">\mathbb{R}^k</script>. For the pre-trained embedding made available by Google at <a href="https://code.google.com/archive/p/word2vec/">this archive</a>, which contains the embedding of around 3 millions of words, <script type="math/tex">k</script> is equals to 300. Indeed, given a vocabulary of <script type="math/tex">n</script> words and fixed a dimension <script type="math/tex">k</script>, a word embedding is given by a matrix <script type="math/tex">\mathbf{X}</script> of dimension <script type="math/tex">n \times k</script>: Row <script type="math/tex">\mathbf{x}_i</script> gives the <script type="math/tex">k</script>-dimensional vector representing the word embedding of word <script type="math/tex">i</script>.</p>

<p>In this case, instead of having discrete measures, we deal with normalized bag-of-words (nBOW), which are vector of <script type="math/tex">\mathbb{R}^n</script>, where <script type="math/tex">n</script> denotes the number of words in the vocabulary. If a text document <script type="math/tex">\mathbf{\mu} \in \mathbb{R}^n</script> contains <script type="math/tex">t_i</script> times the word <script type="math/tex">i</script>, then <script type="math/tex">\mathbf{\mu}_i = \frac{t_i}{\sum_{j=1}^n t_j}</script>. At this point is clear that the <strong>ground distance</strong> between a pair of words is given by the distance between the corresponding embedding vectors in <script type="math/tex">\mathbb{R}^k</script>, that is, given two words <script type="math/tex">i</script> and <script type="math/tex">j</script>, then</p>

<script type="math/tex; mode=display">c(i,j) = \ell_2(\mathbf{x}_i - \mathbf{x}_j)</script>

<p>Finally, given two text documents <script type="math/tex">\mathbf{\mu}</script> and <script type="math/tex">\mathbf{\nu}</script>, we can formulate the Linear Program that gives the <strong>Word Mover Distance</strong> as:</p>

<script type="math/tex; mode=display">\text{WMD}(\mathbf{\mu},\mathbf{\nu}) := \min_{\pi \in U} \sum_{i=1}^n\sum_{j=1}^n c(\mathbf{x}_i, \mathbf{x}_j) \pi_{ij}</script>

<p>where the set <script type="math/tex">U</script> is defined as:</p>

<script type="math/tex; mode=display">% <![CDATA[
U := \left\{\begin{array}{ll}
 \sum_{j=1,\dots,n} \pi_{ij} = \mu_i & i=1,\dots,n \\
 \sum_{i=1,\dots,n} \pi_{ij} = \nu_j& j=1,\dots,n \\
 \pi_{ij} \geq 0 & i=1,\dots,n, j=1,\dots,n. \\
 \end{array}
 \right\}
 %]]></script>

<p>If you are serious reader, and you are still reading this post, then it is clear that the Word Mover Distance is exactly a Kantorovich-Wasserstein distance of order 1, with an Euclidean ground distance. If you are interested in the quality of this distance when used within a nearest neighbor heuristic for a text classification task, we refer to [3]. <em>(While writing this post, I started to wonder how would perform a <strong>WMD</strong> of order 2, but this is another story…)</em></p>

<h3 id="interesting-research-directions">Interesting Research Directions</h3>
<p>The following are the research topics I am interested in right now. Each topic deserves its own blog post, but let me write here just a short sketch.</p>

<ul>
  <li>
    <p><strong>Computational Challenges:</strong> The development of efficient algorithms for the solution of Optimal Transport problems is an active area of research. Currently, the preferred (heuristic) approach is based on so-called <a href="http://marcocuturi.net/SI.html">regularized optimal transport</a>, introduced originally in [5]. Indeed, regularized optimal transport deserves its own blog post.
In two recent works, together with my co-authors, we tried to revive the <a href="https://scholar.google.it/scholar?q=dantzig+network+simplex&amp;hl=en&amp;as_sdt=0&amp;as_vis=1&amp;oi=scholart">Network Simplex</a> for two special cases: Kantorovich-Wasserstein distances of order 1 for <script type="math/tex">k</script>-dimensional histograms [6] and Kantorovich-Wasserstein distances of order 2 for decomposable cost functions [7]. The second paper  was presented as a <a href="https://github.com/stegua/dpartion-nips2018/blob/master/poster/PosterNIPS2018.pdf">poster at NeurIPS2018</a>. <em>(If you ever read any of the two papers, please, let me know what you think about them)</em></p>
  </li>
  <li>
    <p><strong>Unbalanced Optimal Transport:</strong> The computation of Kantorovich-Wasserstein distance for pair of unbalanced discrete measures is very challenging. Last year, a brilliant math student finished a nice project on this topic, which I hope to finalize during the next semester.</p>
  </li>
  <li>
    <p><strong>Barycenters of Discrete Measures:</strong> The Kantorovich-Wasserstein distance can be used to generalize the concept of <em>barycenters</em>, that is, the problem of finding a discrete measure that is the closest (in Kantorovich terms) to a given set of discrete measures. The problem of finding the barycenter can be formulated as a Linear Program, where the unknowns (the decision variables) are both the transport plan and the discrete measure representing the barycenter. For instance, the following images, taken from our last draft paper, represents the barycenters of each of the 10 digits of the <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a> data set of handwritten images (each image is the barycenter of other <script type="math/tex">3\;200</script> images).</p>
  </li>
</ul>

<p><img class="center" src="../../../../../../images/mnist_bary.PNG" /></p>

<ul>
  <li><strong>Distances between Discrete Measures defined on different metric spaces:</strong> This topic is at the top of my 2019 resolutions. There are a few papers by <a href="https://people.math.osu.edu/memoli.2/">Facundo Mémoli</a> on this topic, which are based on the so-called <strong>Gromov-Wasserstein distance</strong> and that requires the solution of a <strong>Quadratic Assignment Problem (QAP)</strong>.</li>
</ul>

<p>Now, it’s time to close this post with final remarks.</p>

<h2 id="optimal-transport-a-brilliant-future">Optimal Transport: A brilliant future?</h2>
<p>Given the number and the quality of results achieved on the Theory of Optimal Transport by “pure” mathematicians, it is the time to turn these theoretical results into a set of useful algorithms implemented in efficient and scalable solvers. So far, the only public library I am aware of is <a href="https://github.com/rflamary/POT">POT: Python Optimal Transport</a>.</p>

<p>On <a href="https://medium.com/">Medium</a>, C.E. Perez claims that <a href="https://medium.com/intuitionmachine/optimal-transport-theory-the-new-math-for-deep-learning-2520395fc183">Optimal Transport Theory (is) the New Math for Deep Learning</a>. In his short post, he explains how Optimal Transport is used in Deep Learning algorithms, specifically in <strong>Generative Adversarial Networks (GANs)</strong>, to replace the <strong>Kullback-Leibler (KL) divergence</strong>.</p>

<p>Honestly, I do not have a clear idea regarding the potential impact of Kantorovich distances on <strong>GANs</strong> and <strong>Deep Learning</strong> in general, but I think there are a lot of research opportunities for everyone with a strong passion for <strong>Computational Combinatorial Optimization</strong>.</p>

<p>And you, what do you think about the topics presented in this post?</p>

<p>As usual, I will be very happy to hear from you, in the meantime…</p>

<blockquote>
  <p><strong>GAME OVER</strong></p>
</blockquote>

<h3 id="acknowledgement">Acknowledgement</h3>
<p>I would like to thank <a href="https://imada.sdu.dk/~marco/">Marco Chiarandini</a>, <a href="https://www.southampton.ac.uk/maths/about/staff/sc2r15.page">Stefano Coniglio</a>, and <a href="http://www-dimat.unipv.it/~bassetti/">Federico Bassetti</a> for constructive criticism of this blog post.</p>

<h3 id="references">References</h3>

<ol>
  <li>
    <p>Villani, C. <span class="title">Optimal transport, old and new.</span> Grundlehren der mathematischen Wissenschaften, Vol.338, Springer-Verlag, 2009. <a href="http://cedricvillani.org/wp-content/uploads/2012/08/B07.StFlour.pdf">[pdf]</a></p>
  </li>
  <li>
    <p>Rubner, Y., Tomasi, C. and Guibas, L.J., 2000. <span class="title">The earth mover&#8217;s distance as a metric for image retrieval.</span> International journal of computer vision, 40(2), pp.99-121. <a href="https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/content/pdf/10.1023/A:1026543900054.pdf&amp;casa_token=Ysv8VHVK29EAAAAA:nIcUgwC_iwnFqj7C1DUcKcVi-JY4FvCt9GQOhNQsa4nmVe_H3BfpO197Y_sakGDwqCfziSHEt3q1Mg">[pdf]</a></p>
  </li>
  <li>
    <p>Kusner, M.J., Sun, Y., Kolkin, N.I., Weinberger, K.Q. <span class="title">From Word Embeddings To Document Distances.</span> Proceedings of the 32 nd International Conference on Machine Learning, Lille, France, 2015. <a href="http://proceedings.mlr.press/v37/kusnerb15.pdf">[pdf]</a></p>
  </li>
  <li>
    <p>Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S. and Dean, J., 2013. <span class="title">Distributed representations of words and phrases and their compositionality.</span> In Advances in neural information processing systems (pp. 3111-3119). <a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">[pdf]</a></p>
  </li>
  <li>
    <p>Cuturi, M., 2013. <span class="title">Sinkhorn distances: Lightspeed computation of optimal transport.</span> In Advances in neural information processing systems (pp. 2292-2300). <a href="https://papers.nips.cc/paper/4927-sinkhorn-distances-lightspeed-computation-of-optimal-transport.pdf">[pdf]</a></p>
  </li>
  <li>
    <p>Bassetti, F., Gualandi, S. and Veneroni, M., 2018. <span class="title">On the Computation of Kantorovich-Wasserstein Distances between 2D-Histograms by Uncapacitated Minimum Cost Flows.</span> arXiv preprint arXiv:1804.00445. <a href="https://arxiv.org/pdf/1804.00445">[pdf]</a></p>
  </li>
  <li>
    <p>Auricchio, G., Bassetti, F., Gualandi, S. and Veneroni, M., 2018. <span class="title">Computing Kantorovich-Wasserstein Distances on d-dimensional histograms using (d+1)-partite graphs. </span> NeurIPS, 2018.<a href="https://arxiv.org/pdf/1805.07416">[pdf]</a></p>
  </li>
</ol>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/01/24/exercise-in-python-remove-blanks-from-strings/">Exercise in Python: Remove Blanks From Strings</a></h1>
    
    
      <p class="meta">
        








  



  
<time datetime="2017-01-24T16:51:00+01:00" pubdate data-updated="true">Jan 24<span>th</span>, 2017</time>
        
         | <a href="/blog/2017/01/24/exercise-in-python-remove-blanks-from-strings/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>This morning, after reading <a href="http://lemire.me/blog/2017/01/20/how-quickly-can-you-remove-spaces-from-a-string/">this very nice post</a>, I decided to challenge myself in Python and to have a look at the impact of <a href="https://en.wikipedia.org/wiki/Branch_misprediction">mispredicted branches</a> in a language different from C/C++. The basic idea was to use only <a href="https://docs.python.org/3.6/library/functions.html">Python builtins</a>: external libraries are not allowed!</p>

<p>As a benchmark, I grabbed a large text file from <a href="http://norvig.com/big.txt">P. Norvig’s website</a>, which is 6’488’666 byte long.</p>

<p><strong>The final answer?</strong> Yes, <strong>mispredicted branches</strong> have a huge impact in Python too.</p>

<p><strong>The hidden answer?</strong> Python dictionaries ever stop to surprise me: they are REALLY efficient.</p>

<p><strong>NOTE</strong>: The followig code snippets were executed in a Python 3.5 notebook, on a windows machine, running Windows 10 and <a href="https://www.continuum.io/downloads">Anaconda Python 3.5 64 bits</a>.
You can find my notebook on my <a href="https://github.com/stegua/MyBlogEntries">Blog GitHub repo</a>. Don’t ask me why, but this blog entry is better visualized directly on <a href="https://github.com/stegua/MyBlogEntries/blob/master/Remove%2Bblanks%2Bfrom%2Ba%2Bstring.ipynb">GitHub</a>.</p>

<p><strong>UPDATE</strong>: Well, most of the time I would use my first implementation based on the <code>filter</code> builtin function, and I would try for alternative implementations only after a profiler has shown
that removing blanks is a true bottleneck of my whole program. As written in the title, this post is meant as a basic exercise in Python.</p>

<h3 id="first-attempt-functional-style">First attempt: Functional style</h3>
<p>In Python, I prefer to write as much code in functional style as possible, relying on the 3 basic functions:</p>

<ol>
  <li><a href="https://docs.python.org/3/library/functions.html#map"><code>map</code></a></li>
  <li><a href="https://docs.python.org/3/library/functions.html#filter"><code>filter</code></a></li>
  <li><a href="https://docs.python.org/3/library/functools.html#functools.reduce"><code>reduce</code></a> (this is in the functools module and it is not a true builtin)</li>
</ol>

<p>Therefore, after few preliminaries, here is my first code snippet:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span></span><span class="kn">import</span> <span class="nn">cProfile</span>
</span><span class="line">
</span><span class="line"><span class="c1"># Download file from: &#39;http://norvig.com/big.txt&#39;</span>
</span><span class="line"><span class="n">big</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;big.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="c1"># Read the while file</span>
</span><span class="line"><span class="n">test</span> <span class="o">=</span> <span class="n">big</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">RemoveBlanksFilter</span><span class="p">(</span><span class="n">in_str</span><span class="p">):</span>
</span><span class="line">    <span class="n">result</span> <span class="o">=</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">c</span><span class="p">:</span> <span class="n">c</span> <span class="o">!=</span> <span class="s1">&#39;</span><span class="se">\r</span><span class="s1">&#39;</span> <span class="ow">and</span> <span class="n">c</span> <span class="o">!=</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span> <span class="ow">and</span> <span class="n">c</span> <span class="o">!=</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">in_str</span><span class="p">)</span>
</span><span class="line">    <span class="k">return</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">test_result</span> <span class="o">=</span> <span class="n">RemoveBlanksFilter</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">cProfile</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s1">&#39;RemoveBlanksFilter(test)&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<pre><code>         6488671 function calls in 1.956 seconds

   Ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    1.955    1.955 &lt;ipython-input-3-eeb7d3495697&gt;:1(RemoveBlanksFilter)
  6488666    0.870    0.000    0.870    0.000 &lt;ipython-input-3-eeb7d3495697&gt;:2(&lt;lambda&gt;)
        1    0.000    0.000    1.956    1.956 &lt;string&gt;:1(&lt;module&gt;)
        1    0.000    0.000    1.956    1.956 {built-in method builtins.exec}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    1.085    1.085    1.955    1.955 {method 'join' of 'str' objects}
</code></pre>

<p>Wow, I didn’t realize that I would have call the lambda function for every single byte of my input file. This is clearly too much overhead.</p>

<h3 id="nd-attempt-remove-function-calls-overhead">2nd attempt: remove function calls overhead</h3>
<p>Let me drop my functional style, and write a plain old for-loop:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span></span><span class="k">def</span> <span class="nf">RemoveBlanks</span><span class="p">(</span><span class="n">in_str</span><span class="p">):</span>
</span><span class="line">    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class="line">    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">in_str</span><span class="p">:</span>
</span><span class="line">        <span class="k">if</span> <span class="n">c</span> <span class="o">!=</span> <span class="s1">&#39;</span><span class="se">\r</span><span class="s1">&#39;</span> <span class="ow">and</span> <span class="n">c</span> <span class="o">!=</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span> <span class="ow">and</span> <span class="n">c</span> <span class="o">!=</span> <span class="s1">&#39; &#39;</span><span class="p">:</span>
</span><span class="line">            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
</span><span class="line">    <span class="k">return</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="k">print</span><span class="p">(</span><span class="s1">&#39;Is test passed:&#39;</span><span class="p">,</span> <span class="n">test_result</span> <span class="o">==</span> <span class="n">RemoveBlanks</span><span class="p">(</span><span class="n">test</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<pre><code>Is test passed: True
</code></pre>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span></span><span class="n">cProfile</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s1">&#39;RemoveBlanks(test)&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<pre><code>         5452148 function calls in 1.566 seconds

   Ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    1.210    1.210    1.553    1.553 &lt;ipython-input-6-5e45e3056bc2&gt;:1(RemoveBlanks)
        1    0.012    0.012    1.566    1.566 &lt;string&gt;:1(&lt;module&gt;)
        1    0.000    0.000    1.566    1.566 {built-in method builtins.exec}
  5452143    0.310    0.000    0.310    0.000 {method 'append' of 'list' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.033    0.033    0.033    0.033 {method 'join' of 'str' objects}
</code></pre>

<p>Mmm… we just shift the problem to the list append function calls. Maybe we can do better by working in place.</p>

<h3 id="rd-attempt-work-in-place">3rd attempt: work in place</h3>
<p>Well, almost in place: Python string are immutable; therefore, we first copy the string into a list, and then we work in place over the copied list.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span></span><span class="k">def</span> <span class="nf">RemoveBlanksInPlace</span><span class="p">(</span><span class="n">in_str</span><span class="p">):</span>
</span><span class="line">    <span class="nb">buffer</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">in_str</span><span class="p">)</span>
</span><span class="line">    <span class="n">pos</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">in_str</span><span class="p">:</span>
</span><span class="line">        <span class="k">if</span> <span class="n">c</span> <span class="o">!=</span> <span class="s1">&#39;</span><span class="se">\r</span><span class="s1">&#39;</span> <span class="ow">and</span> <span class="n">c</span> <span class="o">!=</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span> <span class="ow">and</span> <span class="n">c</span> <span class="o">!=</span> <span class="s1">&#39; &#39;</span><span class="p">:</span>
</span><span class="line">            <span class="nb">buffer</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span>
</span><span class="line">            <span class="n">pos</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class="line">    <span class="k">return</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">buffer</span><span class="p">[:</span><span class="n">pos</span><span class="p">])</span>
</span><span class="line">
</span><span class="line"><span class="k">print</span><span class="p">(</span><span class="s1">&#39;Is test passed:&#39;</span><span class="p">,</span> <span class="n">test_result</span> <span class="o">==</span> <span class="n">RemoveBlanksInPlace</span><span class="p">(</span><span class="n">test</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<pre><code>Is test passed: True
</code></pre>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span></span><span class="n">cProfile</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s1">&#39;RemoveBlanksInPlace(test)&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<pre><code>         5 function calls in 1.158 seconds

   Ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    1.113    1.113    1.145    1.145 &lt;ipython-input-9-99d36ae6359e&gt;:1(RemoveBlanksInPlace)
        1    0.013    0.013    1.158    1.158 &lt;string&gt;:1(&lt;module&gt;)
        1    0.000    0.000    1.158    1.158 {built-in method builtins.exec}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.032    0.032    0.032    0.032 {method 'join' of 'str' objects}
</code></pre>

<p>Ok, working in place does have an impact. Let me go on the true point: avoiding <em>mispredicted branches</em>.</p>

<h3 id="th-attempt-to-avoid-mispredicted-branches">4th attempt: to avoid mispredicted branches</h3>
<p>As in the <a href="http://lemire.me/blog/2017/01/20/how-quickly-can-you-remove-spaces-from-a-string/">original blog post</a>:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span></span><span class="k">def</span> <span class="nf">RemoveBlanksNoBranch</span><span class="p">(</span><span class="n">in_str</span><span class="p">):</span>
</span><span class="line">    <span class="c1"># Build table</span>
</span><span class="line">    <span class="n">table</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class="line">    <span class="k">for</span> <span class="n">ic</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">256</span><span class="p">):</span>
</span><span class="line">        <span class="n">c</span> <span class="o">=</span> <span class="nb">chr</span><span class="p">(</span><span class="n">ic</span><span class="p">)</span>
</span><span class="line">        <span class="k">if</span> <span class="n">c</span> <span class="o">==</span> <span class="s1">&#39;</span><span class="se">\r</span><span class="s1">&#39;</span> <span class="ow">or</span> <span class="n">c</span> <span class="o">==</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span> <span class="ow">or</span> <span class="n">c</span> <span class="o">==</span> <span class="s1">&#39; &#39;</span><span class="p">:</span>
</span><span class="line">            <span class="n">table</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span class="line">        <span class="k">else</span><span class="p">:</span>
</span><span class="line">            <span class="n">table</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="c1"># Removal</span>
</span><span class="line">    <span class="nb">buffer</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">in_str</span><span class="p">)</span>
</span><span class="line">    <span class="n">pos</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">in_str</span><span class="p">:</span>
</span><span class="line">        <span class="nb">buffer</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span>
</span><span class="line">        <span class="n">pos</span> <span class="o">+=</span> <span class="n">table</span><span class="p">[</span><span class="nb">ord</span><span class="p">(</span><span class="n">c</span><span class="p">)]</span>  <span class="c1"># ord() is a function --&gt; bottleneck</span>
</span><span class="line">    <span class="k">return</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">buffer</span><span class="p">[:</span><span class="n">pos</span><span class="p">])</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="k">print</span><span class="p">(</span><span class="s1">&#39;Is test passed:&#39;</span><span class="p">,</span> <span class="n">test_result</span> <span class="o">==</span> <span class="n">RemoveBlanksNoBranch</span><span class="p">(</span><span class="n">test</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<pre><code>Is test passed: True
</code></pre>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span></span><span class="n">cProfile</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s1">&#39;RemoveBlanksNoBranch(test)&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<pre><code>         6489183 function calls in 1.474 seconds

   Ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    1.235    1.235    1.460    1.460 &lt;ipython-input-12-1bd75a3de21d&gt;:1(RemoveBlanksNoBranch)
        1    0.014    0.014    1.474    1.474 &lt;string&gt;:1(&lt;module&gt;)
      256    0.000    0.000    0.000    0.000 {built-in method builtins.chr}
        1    0.000    0.000    1.474    1.474 {built-in method builtins.exec}
  6488666    0.192    0.000    0.192    0.000 {built-in method builtins.ord}
      256    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.033    0.033    0.033    0.033 {method 'join' of 'str' objects}
</code></pre>

<p>Ouch!!! These are getting even worse! Why? Well, ‘ord’ is a function, so we are getting back the overhead of function calls. Can we do better by using a dictionary instead of an array?</p>

<h3 id="th-attempt-use-a-dictionary">5th attempt: use a dictionary</h3>
<p>Let me use a dictionary in order to avoid the ‘ord’ function calls.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span></span><span class="k">def</span> <span class="nf">RemoveBlanksNoBranchDict</span><span class="p">(</span><span class="n">in_str</span><span class="p">):</span>
</span><span class="line">    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">in_str</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">str</span><span class="p">:</span>
</span><span class="line">        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;This function works only for strings&#39;</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="c1"># Build table</span>
</span><span class="line">    <span class="n">table</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class="line">    <span class="k">for</span> <span class="n">ic</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">256</span><span class="p">):</span>
</span><span class="line">        <span class="n">c</span> <span class="o">=</span> <span class="nb">chr</span><span class="p">(</span><span class="n">ic</span><span class="p">)</span>
</span><span class="line">        <span class="k">if</span> <span class="n">c</span> <span class="o">==</span> <span class="s1">&#39;</span><span class="se">\r</span><span class="s1">&#39;</span> <span class="ow">or</span> <span class="n">c</span> <span class="o">==</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span> <span class="ow">or</span> <span class="n">c</span> <span class="o">==</span> <span class="s1">&#39; &#39;</span><span class="p">:</span>
</span><span class="line">            <span class="n">table</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">        <span class="k">else</span><span class="p">:</span>
</span><span class="line">            <span class="n">table</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span class="line">
</span><span class="line">    <span class="c1"># Removal</span>
</span><span class="line">    <span class="nb">buffer</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">in_str</span><span class="p">)</span>
</span><span class="line">    <span class="n">pos</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">in_str</span><span class="p">:</span>
</span><span class="line">        <span class="nb">buffer</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span>
</span><span class="line">        <span class="n">pos</span> <span class="o">+=</span> <span class="n">table</span><span class="p">[</span><span class="n">c</span><span class="p">]</span>
</span><span class="line">    <span class="k">return</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">buffer</span><span class="p">[:</span><span class="n">pos</span><span class="p">])</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="k">print</span><span class="p">(</span><span class="s1">&#39;Is test passed:&#39;</span><span class="p">,</span> <span class="n">test_result</span> <span class="o">==</span> <span class="n">RemoveBlanksNoBranchDict</span><span class="p">(</span><span class="n">test</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<pre><code>Is test passed: True
</code></pre>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span></span><span class="n">cProfile</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s1">&#39;RemoveBlanksNoBranchDict(test)&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<pre><code>         261 function calls in 0.771 seconds

   Ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.724    0.724    0.758    0.758 &lt;ipython-input-15-46ad4c3f0b26&gt;:1(RemoveBlanksNoBranchDict)
        1    0.013    0.013    0.771    0.771 &lt;string&gt;:1(&lt;module&gt;)
      256    0.000    0.000    0.000    0.000 {built-in method builtins.chr}
        1    0.000    0.000    0.771    0.771 {built-in method builtins.exec}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.034    0.034    0.034    0.034 {method 'join' of 'str' objects}
</code></pre>

<p>Oooh, yes! Now we can see that without <strong>mispredicted branches</strong> we can really speed up our algorithm.</p>

<p>Is this the best pythonic solution? No, surely not, but still it is an interesting remark to keep in mind when coding.</p>

<h3 id="final-remark-a-simple-pythonic-solution">Final remark: a simple pythonic solution</h3>
<p>Likely, the simplest pythonic solution is just to use the ‘replace’ string function as follows:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span></span><span class="k">def</span> <span class="nf">RemoveBlanksBuiltin</span><span class="p">(</span><span class="n">in_str</span><span class="p">):</span>
</span><span class="line">    <span class="n">s1</span> <span class="o">=</span> <span class="n">in_str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">&#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</span><span class="line">    <span class="n">s2</span> <span class="o">=</span> <span class="n">s1</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</span><span class="line">    <span class="k">return</span> <span class="n">s2</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="k">print</span><span class="p">(</span><span class="s1">&#39;Is test passed:&#39;</span><span class="p">,</span> <span class="n">test_result</span> <span class="o">==</span> <span class="n">RemoveBlanksBuiltin</span><span class="p">(</span><span class="n">test</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<pre><code>Is test passed: True
</code></pre>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span></span><span class="n">cProfile</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s1">&#39;RemoveBlanksBuiltin(test)&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<pre><code>         7 function calls in 0.065 seconds

   Ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.001    0.001    0.064    0.064 &lt;ipython-input-18-58fd6655cfba&gt;:1(RemoveBlanksBuiltin)
        1    0.001    0.001    0.065    0.065 &lt;string&gt;:1(&lt;module&gt;)
        1    0.000    0.000    0.065    0.065 {built-in method builtins.exec}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        3    0.063    0.021    0.063    0.021 {method 'replace' of 'str' objects}
</code></pre>

<p>Here we are, the best solution is indeed to use a builtin function, whenever it is possible, even if this was not the real aim of this exercise.</p>

<p>Please, let me know if you have some comments or a different solution in Python.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/07/04/column-enumeration/">Graph Coloring: Column Generation or Column Enumeration?</a></h1>
    
    
      <p class="meta">
        








  



  
<time datetime="2015-07-04T16:45:00+02:00" pubdate data-updated="true">Jul 4<span>th</span>, 2015</time>
        
         | <a href="/blog/2015/07/04/column-enumeration/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><style type="text/css">
table { width:100%; }
thead {
   background-color: rgba(0,0,255,0.3);
   color: black;
   text-indent: 14px;
   text-align: left;
}
td { padding:4px; }
tbody tr:nth-child(odd) { background-color: rgba(0, 0, 100, 0.2);  }
tbody tr:nth-child(even) { background-color: rgba(0, 0, 100, 0.1); }
.title { color: #07235F; }
.journal { font-style: italic; }
</style>

<p>In this post, I like to share a simple idea on how to solve to optimality some <a href="http://www.info.univ-angers.fr/pub/porumbel/graphs/">hard instances</a> of the <a href="http://en.wikipedia.org/wiki/Graph_coloring">Graph Coloring</a> problem. This simple idea yields a “new time” record for a couple of hard instances. </p>

<p>To date, the best <strong>exact</strong> approach to solve Graph Coloring 
is based on <em><a href="http://en.wikipedia.org/wiki/Branch_and_price">Branch-and-Price</a></em> [1, 2, 3].
The branch-and-price method is completely different from the Constraint Programming approach I discussed in a <a href="http://stegua.github.io/blog/2013/06/28/gecol/">previous post</a>. A key component of Branch-and-Price is the <em>column generation</em> phase, which is 
intuitively quite simple, but mathematically rather involved for a short blog post.</p>

<p>Here, I want to show you that a modern Mixed Integer Programming (MIP) solver, such as <a href="http://www.gurobi.com/">Gurobi</a> or <a href="http://www-01.ibm.com/software/commerce/optimization/cplex-optimizer/">CPLEX</a>, can solve a few hard instances of graph coloring with the following <em>“null implementation effort”</em>:</p>

<ol>
  <li>Enumerate all possible columns</li>
  <li>Build a <a href="http://en.wikipedia.org/wiki/MPS_%28format%29">.mps</a> instance with those columns</li>
  <li>Use a MIP solver to solve the .mps instance</li>
</ol>

<p>Indeed, in this post we try to answer to the following question:</p>

<blockquote>
  <p>Is there any hope to solve any hard graph coloring instances with this naive approach?</p>
</blockquote>

<h2 id="formulation">Formulation</h2>
<p>Given an undirected graph <script type="math/tex">G=(V,E)</script> and a set of colors <script type="math/tex">K</script>, 
the minimum (vertex) graph coloring problem consists of assigning a color to each vertex,
while every pair of adjacent vertices gets a different color. The objective is to minimize the number of colors used in a solution.</p>

<p>The branch-and-price approach to graph coloring is based on a <em>set covering</em> formulation.
Let <script type="math/tex">S</script> be the collection of all the maximal stable sets of <script type="math/tex">G</script>,
and let <script type="math/tex">S_i \subseteq S</script> be the maximal stable sets that contain the vertex <script type="math/tex">i</script>.
Let <script type="math/tex">\lambda_s</script> be a 0-1 variable equal to 1 if all the vertices in the maximal stable set <script type="math/tex">s \in S</script> 
get assigned the same color. Hence, the set covering model is:</p>

<script type="math/tex; mode=display">\min \sum_{s \in S} \lambda_s \mbox{ such that } \sum_{s \in S_i} \lambda_s \geq 1, \forall i \in N, \lambda_s \in \{0,1\}, \forall s \in S.</script>

<p>Indeed, we <em>“cover”</em> every vertex of <script type="math/tex">G</script> with the minimal number of maximal stable sets.
The issue with this model is the total number of maximal stable sets in <script type="math/tex">G</script>, which <em>is exponential in the number of vertices of G</em>.</p>

<p>Column Generation is a “mathematically elegant” method to by-pass this issue:
it lets you to solve the set covering model by <em>generating</em> a very small subset of the elements in <script type="math/tex">S</script>. This happens by repeatedly solving an auxiliary problem,
called the <em>pricing</em> subproblem. For graph coloring, the pricing subproblem consists of a Maximum Weighted Stable Set problem.
If you are interested in Column Generation, I recommend you to look at the first chapter of
the <a href="http://www.springer.com/gp/book/9780387254852">Column Generation book</a>,
which contains a nice tutorial on the topic, and I would <strong>strongly</strong> recommend reading the nice survey “Selected Topics in Column Generation”, [4].</p>

<blockquote>
  <p>How many maximal stable sets are in a hard graph coloring instance?</p>
</blockquote>

<p>If this number were not so high, we could enumerate all the stable sets in <script type="math/tex">S</script>
and attempt to directly solve the set covering model without resorting to column generation.
However, <em>“high”</em> is a subjective measure, so let me do some computations on my laptop and give you some precise numbers.</p>

<h2 id="hard-instances">Hard instances</h2>
<p>Among the <a href="http://mat.gsia.cmu.edu/COLOR/instances.html">DIMACS instances</a> of Graph Coloring, there are a few instances
proposed by David Johnson, which are still unsolved (in the sense that we have not a computational proof of optimality of the best known upper bounds).</p>

<p>The table below shows the dimensions of these instances. The name of instances are DSJC{n}.{d}, where {n} is the number of vertices and {d} gives the density of the graph (e.g., DSJC125.9 has 125 vertices and 0.9 of density).</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Graph</th>
      <th style="text-align: center">Nodes</th>
      <th style="text-align: center">Edges</th>
      <th style="text-align: center">Max stable sets</th>
      <th style="text-align: center">Enumeration Time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">DSJC125.9</td>
      <td style="text-align: center">125</td>
      <td style="text-align: center">6,961</td>
      <td style="text-align: center">524</td>
      <td style="text-align: center">0.00</td>
    </tr>
    <tr>
      <td style="text-align: left">DSJC250.9</td>
      <td style="text-align: center">250</td>
      <td style="text-align: center">27,897</td>
      <td style="text-align: center">2,580</td>
      <td style="text-align: center">0.01</td>
    </tr>
    <tr>
      <td style="text-align: left">DSJC500.9</td>
      <td style="text-align: center">500</td>
      <td style="text-align: center">112,437</td>
      <td style="text-align: center">14,560</td>
      <td style="text-align: center">0.12</td>
    </tr>
    <tr>
      <td style="text-align: left">DSJC1000.9</td>
      <td style="text-align: center">1,000</td>
      <td style="text-align: center">449,449</td>
      <td style="text-align: center">100,389</td>
      <td style="text-align: center">2.20</td>
    </tr>
    <tr>
      <td style="text-align: left">DSJC125.5</td>
      <td style="text-align: center">125</td>
      <td style="text-align: center">3,891</td>
      <td style="text-align: center">43,268</td>
      <td style="text-align: center">0.53</td>
    </tr>
    <tr>
      <td style="text-align: left">DSJC250.5</td>
      <td style="text-align: center">250</td>
      <td style="text-align: center">15,668</td>
      <td style="text-align: center">1,470,363</td>
      <td style="text-align: center">43.16</td>
    </tr>
    <tr>
      <td style="text-align: left">DSJC500.5</td>
      <td style="text-align: center">500</td>
      <td style="text-align: center">62,624</td>
      <td style="text-align: center">?</td>
      <td style="text-align: center">out of memory</td>
    </tr>
    <tr>
      <td style="text-align: left">DSJC1000.5</td>
      <td style="text-align: center">1,000</td>
      <td style="text-align: center">249,826</td>
      <td style="text-align: center">?</td>
      <td style="text-align: center">out of memory</td>
    </tr>
    <tr>
      <td style="text-align: left">DSJC125.1</td>
      <td style="text-align: center">125</td>
      <td style="text-align: center">736</td>
      <td style="text-align: center">?</td>
      <td style="text-align: center">out of memory</td>
    </tr>
    <tr>
      <td style="text-align: left">DSJC250.1</td>
      <td style="text-align: center">250</td>
      <td style="text-align: center">3,218</td>
      <td style="text-align: center">?</td>
      <td style="text-align: center">out of memory</td>
    </tr>
    <tr>
      <td style="text-align: left">DSJC500.1</td>
      <td style="text-align: center">500</td>
      <td style="text-align: center">12,458</td>
      <td style="text-align: center">?</td>
      <td style="text-align: center">out of memory</td>
    </tr>
    <tr>
      <td style="text-align: left">DSJC1000.1</td>
      <td style="text-align: center">1,000</td>
      <td style="text-align: center">49,629</td>
      <td style="text-align: center">?</td>
      <td style="text-align: center">out of memory</td>
    </tr>
  </tbody>
</table>

<p><br />
As you can see the number of maximal stable sets (i.e. the cardinality of <script type="math/tex">S</script>)
of several instances is not so high, above all for very dense graphs, where the number of stables set is less than the number of edges. However, for sparse graphs, the number of maximal stable sets is too large for the memory available in my laptop.</p>

<p>Now, let me re-state the main question of this post:</p>

<blockquote>
  <p>Can we <strong>enumerate</strong> all the maximal stable sets of <script type="math/tex">G</script> and use a  MIP solver such as <a href="http://www.gurobi.com/">Gurobi</a> or <a href="http://www-01.ibm.com/software/commerce/optimization/cplex-optimizer/">CPLEX</a> to solve any Johnson’s instance of Graph Coloring?</p>
</blockquote>

<h2 id="results">Results</h2>
<p>I have written a small script which uses <a href="http://users.aalto.fi/~pat/cliquer.html">Cliquer</a> to enumerate all the maximal
stable sets of a graph, and then I generate an <a href="http://en.wikipedia.org/wiki/MPS_%28format%29">.mps</a>
instance for each of the DSJC instance where I was able to store all maximal stable sets.
The .mps file are on my public <a href="https://github.com/stegua/MyBlogEntries/tree/master/Coloring">GitHub repository for this post</a>.</p>

<p>The table below shows some numbers for the sparse instances obtained using Gurobi (v6.0.0)
with a timeout of 10 minutes on my laptop. If you compare these numbers with the results published in the literature, you can see that they are not bad at all.</p>

<p>Believe me, these number are not bad at all, and establish a new <strong>TIME RECORD</strong>.</p>

<p>For example, the instance DSJC250.9 was solved to optimality only recently in
11094 seconds by [3], while the column enumeration approach solves the same instance on a similar hardware in only 23 seconds (!), and, honestly, our work in [2] did not solve this instance to optimality at all.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Graph</th>
      <th style="text-align: center">Best known</th>
      <th style="text-align: center">Enum. Time</th>
      <th style="text-align: center">Run time</th>
      <th style="text-align: center">LB</th>
      <th style="text-align: center">UB</th>
      <th style="text-align: center">Time [2]</th>
      <th style="text-align: center">LB[2]</th>
      <th style="text-align: center">UB [2]</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">DSJC125.9</td>
      <td style="text-align: center"><strong>44</strong></td>
      <td style="text-align: center">0.00</td>
      <td style="text-align: center"><strong>0.44</strong></td>
      <td style="text-align: center"><strong>44</strong></td>
      <td style="text-align: center"><strong>44</strong></td>
      <td style="text-align: center">44</td>
      <td style="text-align: center"><strong>44</strong></td>
      <td style="text-align: center"><strong>44</strong></td>
    </tr>
    <tr>
      <td style="text-align: left">DSJC250.9</td>
      <td style="text-align: center"><strong>72</strong></td>
      <td style="text-align: center">0.01</td>
      <td style="text-align: center"><strong>23</strong></td>
      <td style="text-align: center"><strong>72</strong></td>
      <td style="text-align: center"><strong>72</strong></td>
      <td style="text-align: center">timeout</td>
      <td style="text-align: center">71</td>
      <td style="text-align: center">72</td>
    </tr>
    <tr>
      <td style="text-align: left">DSJC500.9</td>
      <td style="text-align: center">128</td>
      <td style="text-align: center">0.12</td>
      <td style="text-align: center">timeout</td>
      <td style="text-align: center">123</td>
      <td style="text-align: center"><strong>128</strong></td>
      <td style="text-align: center">timeout</td>
      <td style="text-align: center">123</td>
      <td style="text-align: center">136</td>
    </tr>
    <tr>
      <td style="text-align: left">DSJC1000.9</td>
      <td style="text-align: center">222</td>
      <td style="text-align: center">2.20</td>
      <td style="text-align: center">timeout</td>
      <td style="text-align: center">215</td>
      <td style="text-align: center"><strong>229</strong></td>
      <td style="text-align: center">timeout</td>
      <td style="text-align: center">215</td>
      <td style="text-align: center">245</td>
    </tr>
    <tr>
      <td style="text-align: left">DSJC125.5</td>
      <td style="text-align: center"><strong>17</strong></td>
      <td style="text-align: center">0.53</td>
      <td style="text-align: center"><strong>70.6</strong></td>
      <td style="text-align: center"><strong>17</strong></td>
      <td style="text-align: center"><strong>17</strong></td>
      <td style="text-align: center">19033</td>
      <td style="text-align: center"><strong>17</strong></td>
      <td style="text-align: center"><strong>17</strong></td>
    </tr>
    <tr>
      <td style="text-align: left">DSJC250.5</td>
      <td style="text-align: center">28</td>
      <td style="text-align: center">43.16</td>
      <td style="text-align: center">timeout</td>
      <td style="text-align: center">26</td>
      <td style="text-align: center">33</td>
      <td style="text-align: center">timeout</td>
      <td style="text-align: center">26</td>
      <td style="text-align: center">31</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<blockquote>
  <p>Can we ever solve to optimality DSJC500.9 and DSJC1000.9 via Column Enumeration?</p>
</blockquote>

<p>I would say:</p>

<blockquote>
  <p>“Yes, we can!”</p>
</blockquote>

<p>… but likely we need to be smarter while branching on the decision variables, since the default branching strategy of a generic MIP solver does not exploit the structure of the problem. If I had the time to work again on Graph Coloring, I would likely use the same branching scheme used in [2], where we combined a Zykov’s branching rule with a randomized <a href="http://en.wikipedia.org/wiki/Iterative_deepening_depth-first_search">iterative deepening depth-first search</a> (randomised because at each restart we were using a different initial pool of columns). Another interesting option would be to tighten the set covering formulation with valid inequalities, by starting with those studied in [5]. </p>

<p>In conclusion, I believe that enumerating all columns can be a simple but good starting point to attempt to solve to optimality at least the instances DSJC500.9 and DSJC1000.9.</p>

<p>Do you have some spare time and are you willing to take up the challenge?</p>

<h2 id="references">References</h2>
<ol>
  <li>
    <p>A Mehrotra, MA Trick.
<span class="title">A column generation approach for graph coloring</span>.
<span class="journal">INFORMS Journal on Computing</span>. Fall 1996 vol. 8(4), pp.344-354. 
<a href="http://joc.journal.informs.org/content/8/4/344.short ">[pdf]</a></p>
  </li>
  <li>
    <p>S. Gualandi and F. Malucelli.
<span class="title">Exact Solution of Graph Coloring Problems via Constraint Programming and Column Generation</span>.
<span class="journal">INFORMS Journal on Computing</span>. Winter 2012 vol. 24(1), pp.81-100. 
<a href="http://joc.journal.informs.org/content/24/1/81.short">[pdf]</a>
<a href="http://www.optimization-online.org/DB_FILE/2010/03/2568.pdf">[preprint]</a></p>
  </li>
  <li>
    <p>S. Held, W. Cook, E.C. Sewell.
<span class="title">Maximum-weight stable sets and safe lower bounds for graph coloring</span>.
<span class="journal">Mathematical Programming Computation</span>. December 2012, Volume 4, Issue 4, pp 363-381.
<a href="http://link.springer.com/content/pdf/10.1007%2Fs12532-012-0042-3.pdf">[pdf]</a></p>
  </li>
  <li>
    <p>M. Lubbecke and J. Desrosiers.
<span class="title">Selected topics in column generation</span>.
<span class="journal">Operations Research</span>. 2005, Volume 53, Issue 6, pp 1007-1023.
<a href="http://pubsonline.informs.org/doi/abs/10.1287/opre.1050.0234">[pdf]</a></p>
  </li>
  <li>
    <p>
<span class="title">Set covering and packing formulations of graph coloring: algorithms and first polyhedral results</span>.
<span class="journal">Discrete Optimization</span>. 2009, Volume 6, Issue 2, pp 135-147.
<a href="http://www.sciencedirect.com/science/article/pii/S1572528608000716">[pdf]</a></p>
  </li>
</ol>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/09/27/big-data-and-convex-optimization/">Big Data and Convex Optimization</a></h1>
    
    
      <p class="meta">
        








  



  
<time datetime="2014-09-27T16:38:00+02:00" pubdate data-updated="true">Sep 27<span>th</span>, 2014</time>
        
         | <a href="/blog/2014/09/27/big-data-and-convex-optimization/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In the last months, I came several times across different definitions of <strong>Big Data</strong>.
However, when someone asks me what Big Data means in practice, I am never
able to give a satisfactory explanation. Indeed, you can easily find a flood
of posts on twitter, blogs, newspaper, and even scientific journals and conferences,
but I always kept feeling that <strong>Big Data</strong> is a buzzword.</p>

<p>By sheer serendipity, this morning I came across <a href="http://web.stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf">three paragraphs</a> clearly
stating the importance of Big Data from a scientific standpoint, that I like to <strong>cross-post</strong> here (the following paragraphs appear in the introduction of [1]):</p>

<p><em>In all applied fields, it is now commonplace to attack problems through data analysis, particularly through the use of statistical and machine learning algorithms on what are often large datasets. In industry, this trend has been referred to as ‘Big Data’, and it has had a significant impact in areas as varied as artificial intelligence, internet applications, computational biology, medicine, finance, marketing, journalism, network analysis, and logistics.</em></p>

<p><em>Though these problems arise in diverse application domains, they share some key characteristics. First, the datasets are often extremely large, consisting of hundreds of millions or billions of training examples; second, the data is often very high-dimensional, because it is now possible to measure and store very detailed information about each example; and third, because of the large scale of many applications, the data is often stored or even collected in a distributed manner. As a result, it has become of central importance to develop algorithms that are both rich enough to capture the complexity of modern data, and scalable enough to process huge datasets in a parallelized or fully decentralized fashion. Indeed, some researchers have suggested that even highly complex and structured problems may succumb most easily to relatively simple models trained on vast datasets.</em></p>

<blockquote>
  <p>Many such problems can be posed in the framework of <strong>Convex Optimization</strong>. </p>
</blockquote>

<p><em>Given the significant work on decomposition methods and decentralized algorithms in the optimization community, it is natural to look to parallel optimization algorithms as a mechanism for solving large-scale statistical tasks. This approach also has the benefit that one algorithm could be flexible enough to solve many problems.</em></p>

<p>Even if I am not an expert of Convex Optimization [2], I do have my own <strong>mathematical optimization</strong> bias. 
Likely, you may have a different opinion (that I am always happy to hear), but, honestly, the above paragraphs
are the best content that I have read so far about <strong>Big Data</strong>.</p>

<h3 id="references">References</h3>

<p>[1] S. Boyd, N. Parikh, E. Chu, B. Peleato, J. Eckstein.
<em>Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers</em>.
Foundations and Trends in Machine Learning. Vol. 3, No. 1 (2010) 1–122. <a href="http://web.stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf">[pdf]</a></p>

<p>[2] If you like to have a speedy overview of <em>Convex Optimization</em>, you may read a <a href="https://www.ibm.com/developerworks/community/blogs/jfp/entry/convex_optimization?lang=en">J.F. Puget’s blog post</a>.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/03/19/the-impact-of-preprocessing/">The Impact of Preprocessing on the MIPLIB2003</a></h1>
    
    
      <p class="meta">
        








  



  
<time datetime="2014-03-19T22:38:00+01:00" pubdate data-updated="true">Mar 19<span>th</span>, 2014</time>
        
         | <a href="/blog/2014/03/19/the-impact-of-preprocessing/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>What do you know about <strong>preprocessing</strong> for <em>Mixed Integer Programming (MIP)</em> problems?</p>

<p>After a nice chat with <a href="http://dk.linkedin.com/in/bojensen">Bo Jensen</a>, CEO, founder, and co-owner (really, he is a Rocket Scientist!) at <a href="http://www.sulumoptimization.com/">Sulum Optimization</a>, I realised that I know barely anything.</p>

<p>By definition, we have that:</p>

<blockquote>
  <p>“Presolving is a way to transform the given problem instance into an equivalent instance that is (hopefully) easier to solve.” (see, chap. 10 in <a href="http://nbn-resolving.de/urn:nbn:de:0297-zib-11129">Tobias Achterberg’s Thesis</a>)</p>
</blockquote>

<p>All I know is that every MIP solver has a <strong>Presolve</strong> parameter, which can take different values.
For instance, <a href="http://www.gurobi.com">Gurobi</a> has three possible values for that parameter (you can find more details on the <a href="http://www.gurobi.com/documentation/5.0/reference-manual/node718#parameter:Presolve">Gurobi online manual</a>):</p>

<ul>
  <li><em>Presolve=0</em>: no presolve at all</li>
  <li><em>Presolve=1</em>: standard presolve</li>
  <li><em>Presolve=2</em>: aggressive presolve: “More aggressive application of presolve takes more time, but can sometimes lead to a significantly tighter model.”</li>
</ul>

<p>However, I can’t tell you the real <strong>impact</strong> of that parameter on the overall solution process of a MIP instance. Thus, here we go: let me write a new post that addresses this basic question!</p>

<h2 id="how-to-measure-the-impact-of-preprocessing">How to measure the Impact of Preprocessing?</h2>
<p>To measure the impact of preprocessing we need four ingredients:</p>

<ol>
  <li>A MIP solver</li>
  <li>A Data set</li>
  <li>Computer power</li>
  <li>A method to <strong>measure</strong> the impact of preprocessing</li>
</ol>

<p>Changing one of the ingredients could give you different results, but, hopefully, the big picture will not change too much.</p>

<p>As a solver, I have selected the current release of Gurobi (i.e., version 5.6.2). For the data set, likely the most critical ingredient, I have used the <a href="http://miplib.zib.de/miplib2003/">MIPLIB2003</a>, basically because I had already all the 60 instances on my server. For running the test I have used an old cluster from the <a href="http://www-dimat.unipv.it">Math Department</a> of University of Pavia.</p>

<p>The <strong>measure of impact</strong> I have decided to use (after considering other alternatives) is quite conservative: the fraction of closed instances as a function of runtime.</p>

<p>During the last weekend, I have collected a bunch of logs for the 60 instances of the MIPLIB2003, and, then, using <a href="http://www.rstudio.com">RStudio</a>, I have draw the following cumulative plot:</p>

<p><img class="center" src="../../../../../../images/preprocessing.png" /></p>

<p>The picture is as simple as clear:</p>

<blockquote>
  <p>Preprocessing does always pay-off and permits to solve around 10% more of the instances within the same time limit!</p>
</blockquote>

<p>In this post, I will not discuss additional technical details, but I just want to add two observations:</p>

<ol>
  <li>Standard preprocessing has removed in average 20.3% of nonzero entries of the original model, while aggressive preprocessing has removed 22.5% of nonzero entries, only a few more.</li>
  <li>The average MIP gaps as reported by Gurobi at timeout are: no-presolve = 13.44%, standard = 9.08%, and aggressive = 11.02%.</li>
</ol>

<p>Likely, the aggressive presolve setting has been decided by Gurobi using a different, much larger, and customer-oriented dataset.</p>

<h2 id="open-questions">Open Questions</h2>
<p>Indeed, preprocessing is a very important feature of a modern MIP solver as Gurobi. Investing few seconds before starting the branch-and-bound MIP search can save a significant amount of runtime. However, a more aggressive preprocessing strategy does not seem to payoff, in average, on the MIPLIB2003.</p>

<p>Unfortunately, preprocessing is somehow disregarded from the research community. There are few recent papers dealing with preprocessing (<em>“ehi! if you do have one, please, let me know about it, ok?”</em>).
Most of papers are from the 90s and about Linear Programming, i.e., without integer variables, which mess up everything.</p>

<p>Here a list of basic questions I have in mind:</p>

<ul>
  <li>If cutting planes are used to approximate the convex hull of an Integer Problem, preprocessing for what is used for, really?</li>
  <li>Preprocessing techniques have been designed considering a trade-off between <strong>efficiency</strong> and <strong>efficacy</strong> (see, MWP Savelsbergh, <em>Preprocessing and Probing Techniques for MIP problems</em>, Journal of Computing, vol6(4) 445-454, 1995). With recent progress in software and hardware technologies, can we revise this trade-off in favor of efficacy?</li>
  <li>Preprocessing techniques used for Linear Programming are effective when applied to LP relaxations of Integer Problems?</li>
  <li>Should preprocessing sparsify the coefficient matrix?</li>
  <li>Using the more recent <a href="http://miplib.zib.de/">MIPLIB2010</a> should we expect much different results?</li>
  <li>Which is a better method to measure the impact of preprocessing on a collection of instances?</li>
</ul>

<p>If you want to share your idea, experience, or opinion, with respect to these questions, you could comment below or send me an email.</p>

<p>Now, to conclude, my bonus question:</p>

<blockquote>
  <p>Do you have any new smart idea for improving preprocessing?</p>
</blockquote>

<p>Well, if you had, I guess you would at least write a paper about, but, do not go for a patent, please!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/01/13/informal-report-from-cow-at-aussois-2014/">An Informal Report From the Combinatorial Optimization Workshop @ Aussois 2014</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-01-13T18:30:00+01:00" pubdate data-updated="true">Jan 13<span>th</span>, 2014</time>
        
         | <a href="/blog/2014/01/13/informal-report-from-cow-at-aussois-2014/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>It is very hard to report about the <a href="http://www.iasi.cnr.it/aussois/web/home">Combinatorial Optimization Workshop</a> in <a href="http://www.aussois.com/hiver/">Aussois</a>. It was like an “informal” <a href="http://www.or.uni-bonn.de/ipco/">IPCO</a> with <em>Super Heroes researchers</em> in the audience, leaded by <em>Captain Egon</em>, who appears at work in the following photo-tweet:</p>

<blockquote class="twitter-tweet" lang="en"><p>Egon talks intersection cuts at <a href="https://twitter.com/search?q=%23aussois&amp;src=hash">#aussois</a>. Still the man. <a href="http://t.co/7KMcNyJYV0">pic.twitter.com/7KMcNyJYV0</a></p>&mdash; Jeff Linderoth (@JeffLinderoth) <a href="https://twitter.com/JeffLinderoth/statuses/420852308583276544">January 8, 2014</a></blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>The Captain gave an inspiring talk by questioning the recursive paradigm of cutting planes algorithms. With a very basic example, <a href="http://public.tepper.cmu.edu/facultydirectory/FacultyDirectoryProfile.aspx?id=39">Balas</a> has shown how a non basic vertex (solution) can produce a much deeper cut than a cut generated by an optimal basis. Around this intuition, Balas has presented a very nice <a href="http://link.springer.com/article/10.1007%2Fs10107-011-0483-x">generalization of Intersection Cuts</a>… a new paper enters my “PAPERS-TO-BE-READ” folder.</p>

<p>To stay on the subject of cutting planes, the talk by Marco Molinaro in the first day of the workshop was really nice. He raises the fundamental question on how important are <strong>sparse cuts</strong> versus <strong>dense cuts</strong>. The importance of sparse cuts comes from linear algebra: when solving the simplex it is better to have small determinants in the coefficient matrix of the Linear Programming relaxation in order to avoid numerical issues; sparse cuts implicitly help in keeping small the determinants (intuitively, you have more zeros in the matrix). Dense cuts play the opposite role, but they can be really important to improve the bound of the LP relaxation.
In his talk, Molinaro has shown and proofed, for three particular cases, when sparse cuts are enough, and when they are not. 
Another paper goes on the “PAPERS-TO-BE-READ” folder.</p>

<p>In the same day of Molinaro, it was really inspiring the talk by Sebastian Pokutta, who really gave a completely new (for me) perspective on <strong>Extended Formulations</strong> by using <a href="http://en.wikipedia.org/wiki/Information_theory">Information Theory</a>. Sebastian is the author of a <a href="http://spokutta.wordpress.com/">blog</a>, and I hope he will post about his talk.</p>

<p>Andrea Lodi has discussed about an Optimization problem that arises in Supervised Learning.  For this problem, the COIN-OR solver <a href="http://www.coin-or.org/Couenne/">Couenne</a>, developed by Pietro Belotti, significantly outperforms <a href="http://www-01.ibm.com/software/commerce/optimization/cplex-optimizer/">CPLEX</a>. The issues seem to come from on a number of basic big-M (indicator) constraints. To make a long story short, if you have to solve a hard problem, it does pay off to try different solvers, since there is not a “win-all” solver. </p>

<blockquote>
  <p>Do you have an original new idea for developing solvers? Do not be intimidated by <a href="http://www-01.ibm.com/software/commerce/optimization/cplex-optimizer/">CPLEX</a> or <a href="http://www.gurobi.com/">Gurobi</a> and go for it!</p>
</blockquote>

<p>The presentation by Marco Senatore was brilliant and his work looks very interesting. I have particularly enjoyed the application in Public Transport that he has mentioned at the end of his talk.</p>

<p>I recommend to have a look at the presentation of Stephan Held about the <strong>Reach-aware Steiner Tree Problem</strong>. He has an interesting Steiner tree-like problem with a very important application in chip design. The presentation has impressive pictures of what optimal solutions look like in chip design.</p>

<p>At the end of talk, Stephan announced the <a href="http://dimacs11.cs.princeton.edu/">11th DIMACS challenge on Steiner Tree Problems</a>.</p>

<p>Eduardo Uchoa gave another impressive presentation on recent progresses on the classical <strong>Capacitated Vehicle Routing Problem</strong> (CVRP). He has a very sophisticated branch-and-price-and-cut algorithm, which comes with a very efficient implementation of every possible idea developed for CVRP, plus new ideas on solving efficiently the pricing sub problems (my understanding, but I might be wrong, is that they have a very efficient dominance rule for solving a shortest path sub problem). 
+1 item in the “PAPERS-TO-BE-READ” folder.</p>

<p>The last day of the workshop, I have enjoyed the two talks by Simge Kucukyavuz and Jim Luedtke on <strong>Stochastic Integer Programming</strong>: for me is a completely new topic, but the two presentations were really inspiring.</p>

<p>To conclude, Domenico Salvagnin has shown how far it is possible to go by carefully using MIP technologies such as <strong>cutting planes</strong>, <strong>symmetry handling</strong>, and <strong>problem decomposition</strong>. Unfortunately, it does happen too often that when someone (typically a non OR expert) has a difficult application problem, he writes down a more or less complicated Integer Programming model, tries a solver, sees it takes too much time, and gives up with exact methods. Domenico, by solving the largest unsolved instance for the 3-dimensional assignment problem, has shown that </p>

<blockquote>
  <p>there are potentially no limits for MIP solvers!</p>
</blockquote>

<p>In this post, I have only mentioned a few talks, which somehow overlap with my research interests. However, every talk was really interesting. Fortunately, Francois Margot has strongly encouraged all of the speakers to upload their slides and/or papers, so you can find (almost) all of them on the <a href="http://www.iasi.cnr.it/aussois/web/home/program/year/2014">program web page of the workshop</a>. Visit the website and have a nice reading!</p>

<p>To conclude, let me steal another nice picture from twitter: </p>

<blockquote class="twitter-tweet" lang="en"><p>Goodbye <a href="https://twitter.com/search?q=%23aussois2014&amp;src=hash">#aussois2014</a> <a href="http://t.co/ODupKKmGTZ">pic.twitter.com/ODupKKmGTZ</a></p>&mdash; Matteo Fischetti (@MFischetti) <a href="https://twitter.com/MFischetti/statuses/421642338759618560">January 10, 2014</a></blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/11/17/public-transport-and-big-data/">Public Transport and Big Data</a></h1>
    
    
      <p class="meta">
        








  



  
<time datetime="2013-11-17T14:10:00+01:00" pubdate data-updated="true">Nov 17<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/11/17/public-transport-and-big-data/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>Big Data</strong> is nowadays a <em>buzzword</em>. A simple query for “Big Data” on Google gives about 26,700,000 results. </p>

<p><strong>Public Transport</strong> is not really a <em>buzzword</em>, but still on Google you can get almost the same number as with “Big Data”: 26,400,000 results.</p>

<h3 id="why-is-public-transport-so-important">Why is Public Transport so important?</h3>

<p>Because <em>many</em> of us use <a href="http://en.wikipedia.org/wiki/Public_transport">Public Transport</a> every day, but <em>most</em> of us still use their own car to go to work, to bring child at school, and to go shopping. This has a negative impact on the quality of life of everyone and is clearly inefficient since it does cost more: </p>

<ol>
  <li>More money.</li>
  <li>More pollution.</li>
  <li>More time.</li>
</ol>

<p>(Well, for time, it is not always true, but it happens more often than commonly perceived). </p>

<p>Thus, an important <strong>challenge</strong> is to improve the quality of Public Transport while keeping 
its cost competitive. The ultimate goal should be to increase the number of people that <strong>trust</strong> and use Public Transport.</p>

<p>How is it possible to achieve this goal?</p>

<h3 id="transport-operators-are-big-data-producers-are-they">Transport Operators are <strong>Big Data</strong> producers (are they?)</h3>

<p>Modern transport operators have installed so called <em>Automatic Vehicle Monitoring (AVM)</em> systems that use several technologies to monitor the fleet of vehicles that operates the service (e.g., metro coaches, buses, metro trains, trains, …).</p>

<p>The stream of data produced by an AVM might be considered as <strong>Big Data</strong> because of its <strong>volume</strong> and <strong>velocity</strong> (see <a href="https://www.ibm.com/developerworks/community/blogs/jfp/entry/big_data_for_dummies23?lang=en">Big Data For Dummies</a>, by J.F. Puget). Each vehicle produces at regular intervals (measured in seconds) data concerning its position and status. This information is stored in remote data centers. The data for a single day might not be considered as “Big”, however once you start to analyze the historical data, the volume increases significantly. For instance, a public transport operator could easily have around 2000 thousands vehicles that operate 24 hours a day, producing data potentially every second.</p>

<p>At the moment, this stream of data misses the third dimension of Big Data that is <strong>variety</strong>. However, new projects that aim at integrating this information with the stream of data coming from social networks are quickly reaching maturity. One of such project is <a href="http://www.superhub-project.eu/">SuperHub</a>, a FP7 project that has recently won the best exhibit award in Cluster 2 <em>“Smart and sustainable cities for 2020+”</em>, at the <a href="http://www.superhub-project.eu/media-centre/124-ict2013-conference-best-exhibit-award-.html">ICT2013 Conference</a> in Vilnius.</p>

<p>I don’t know whether transport operators are really <strong>Big Data</strong> producers or they are merely <strong>Small Data</strong> producers, but data collected using AVMs are nowadays mainly used to report and monitor the daily activities.</p>

<p>In my own opinion, the data produced by transport operators, integrated with input coming from social networks, should be used to improve the quality of the public transport, for instance, by trying to better tackle <strong>Disruption Management</strong> issues.</p>

<p>So, I am curious:</p>

<blockquote>
  <p>Do you know any project that uses AVM data, combined with Social Network inputs (e.g., from <a href="http://www.twitter.com">Twitter</a>), to elaborate <strong>Disruption Management</strong> strategies for Public Transport? If yes, do they use <strong>Mathematical Optimization</strong> at all?</p>
</blockquote>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/11/01/reading-excuses/">Reading Excuses</a></h1>
    
    
      <p class="meta">
        








  



  
<time datetime="2013-11-01T15:56:00+01:00" pubdate data-updated="true">Nov 1<span>st</span>, 2013</time>
        
         | <a href="/blog/2013/11/01/reading-excuses/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I love reading!</p>

<p>I love reading about everything and I am glad that part of my work consists in reading.</p>

<p>Unfortunately, for researchers, reading is not always that easy, as clearly explained in <strong><a href="http://homepages.inf.ed.ac.uk/bundy/how-tos/resbible.html">The Researcher’s Bible</a></strong>:</p>

<blockquote>
  <p>Reading is difficult: The difficulty seems to depend on the stage of academic development. Initially it is hard to know what to read (many documents are unpublished), later reading becomes seductive and is used as an excuse to avoid research. Finally one lacks the time and patience to keep up with reading (and fears to find evidence that one’s own work is second rate or that one is slipping behind)</p>
</blockquote>

<p>For my <em>stage of academic development</em>, reading is <strong>extremely seductive</strong>, and the situation became even worse after reading the answers to the following question raised by <a href="http://mat.tepper.cmu.edu/blog">Michael Trick</a> on <a href="https://www.or-exchange.org/">OR-exchange</a>:</p>

<blockquote>
  <p><a href="https://www.or-exchange.org/questions/681/what-paper-should-everyone-read">What paper should everyone read?</a></p>
</blockquote>

<p>If you are looking for excuses to avoid research, go through <a href="https://www.or-exchange.org/questions/681/what-paper-should-everyone-read">those answers</a> and select any paper you like, you will have <strong>outstanding</strong> and <strong>authoritative</strong> excuses!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/06/28/gecol/">GeCol: A Graph Coloring Solver on Top of Gecode</a></h1>
    
    
      <p class="meta">
        








  



  
<time datetime="2013-06-28T15:00:00+02:00" pubdate data-updated="true">Jun 28<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/06/28/gecol/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><style type="text/css">
.title { color: #07235F; }
.journal { font-style: italic; }
</style>

<p>This post is about solving the classical <strong>Graph Coloring</strong> problem by using a simple solver, named here <strong>GeCol</strong>, that is built on top of the Constraint Programming (CP) solver <a href="http://www.gecode.org">Gecode</a>. The approach of GeCol is based on the CP model described in [1]. Here, we want to explore some of the new features of the last version of Gecode (version 4.0.0), namely: </p>

<ul>
  <li><em>Lightweight Dynamic Symmetry Breaking (LDSB)</em> [2]</li>
  <li><em>Accumulated Failure Count (AFC)</em> and <em>Activity-based</em> strategies for variable selection while branching, combined with <em>Restart Based Search</em></li>
</ul>

<p>We are going to present computational results using these features to solve the <a href="https://sites.google.com/site/graphcoloring/vertex-coloring">instances</a> of the <a href="http://dimacs.rutgers.edu/Challenges/">Graph Coloring DIMACS Challenge</a>. However, this post is not going to describe in great details what these features are: please, for this purpose, refer to the <a href="http://www.gecode.org/doc-latest/MPG.pdf">Modeling and Programming with Gecode</a> book.</p>

<p>As usual, all the sources used to write this post are publicly available on 
<a href="https://github.com/stegua/MyBlogEntries/tree/master/Coloring">my GitHub repository</a>.</p>

<h3 id="modeling-graph-coloring-with-constraint-programming">Modeling Graph Coloring with Constraint Programming</h3>

<p>Given an undirected graph <script type="math/tex">G=(V,E)</script> and a set of colors <script type="math/tex">K</script>, the minimum (vertex) graph coloring problem consists of assigning a color to each vertex, while every pair of adjacent vertices gets a different color. The objective is to minimize the number of colors.</p>

<p>To model this problem with CP, we can use for each vertex <script type="math/tex">i</script> an integer variable <script type="math/tex">x_i</script> with domain equals to <script type="math/tex">K</script>: if <script type="math/tex">x_i=k</script>, then color <script type="math/tex">k</script> is assigned to vertex <script type="math/tex">i</script>.
Using (inclusion-wise) <em>maximal cliques</em>, it is possible to post constraints on subsets of adjacent vertices: every subset of vertices belonging to the same clique must get a different color. In CP, we can use the well-known <code>alldifferent</code> constraint for posting these constraints.</p>

<p>In practice, to build our CP model, first, we find a collection of maximal cliques <script type="math/tex">C</script>, such that for every edge <script type="math/tex">(i,j) \in E</script> there exists at least a clique <script type="math/tex">c \in C</script> that contains both vertices <script type="math/tex">i</script> and <script type="math/tex">j</script>. Second, we post the following constraints:</p>

<script type="math/tex; mode=display">\mbox{alldifferent}([x_c]) \qquad \forall c \in C</script>

<p>where <script type="math/tex">x_c</script> denotes the subset of variables corresponding to the vertices that belong to the clique <script type="math/tex">c</script>.</p>

<p>In order to minimize the number of colors, we use a simple iterative procedure. Every time we found a coloring with <script type="math/tex">k</script> colors, we restart the search by restricting the cardinality of <script type="math/tex">K</script> to <script type="math/tex">k-1</script>. If no feasible coloring exists with <script type="math/tex">k-1</script> colors, we have proved optimality for the last feasible coloring found, i.e. <script type="math/tex">\chi(G)=k</script>.</p>

<p>In addition, we apply a few basic preprocessing steps that are described in [1].
The maximal cliques are computed using <strong>Cliquer v1.21</strong> [5].</p>

<h3 id="lightweight-dynamic-symmetry-breaking">Lightweight Dynamic Symmetry Breaking</h3>

<p>The Graph Coloring problem is an optimization problem that has several equivalent optimum solutions: for instance, given an optimal assignment of colors to vertices, any permutation of the colors, gives a solution with the same optimum value.</p>

<p>While this property is implicitly considered in <em>Column Generation approaches</em> to Graph Coloring (e.g., see [3], [1], and [4]), the CP model we have just presented, suffers from symmetries issues: the values of the domains of the integer variables are symmetric.</p>

<p>The <strong>Lightweight Dynamic Symmetry Breaking</strong> is a strategy for dealing with this issue [2].
In Gecode, you can define a set of values that are symmetric as follows:</p>

<p><code>Symmetries syms;
 syms &lt;&lt; ValueSymmetry(IntArgs::create(k,1));</code></p>

<p>and then when posting the branching strategy you just write (just note that use of object <code>syms</code>):</p>

<p><code>branch(*this, x, INT_VAR_SIZE_MIN(), INT_VAL_MIN(), syms);</code></p>

<p>With <strong><em>three lines of code</em></strong>, you have solved (some of) the symmetry issues.</p>

<blockquote>
  <p>How efficient is <em>Lightweight Dynamic Symmetry Breaking</em> for Graph Coloring?</p>
</blockquote>

<p>We try to answer to this question with the plot below that shows the results for two versions of GeCol:</p>

<ul>
  <li>(A) The first version without any breaking symmetry strategy</li>
  <li>(B) The second version with the Lightweight Dynamic Breaking Symmetry</li>
</ul>

<p>Both versions select for branching the variable with the smallest domain size.
The plot reports the empirical cumulative distribution as function of run time (in log-scale).
The tests were run with a timeout of 300 seconds on a quite old server. 
Note that at the timeout, the version with LDBS has solved around 55% of the instances, while the version without LDBS has solved only around 48% of the instances.</p>

<p><img class="center" src="../../../../../../images/Ecdf1.png" /></p>

<h3 id="accumulated-failure-count-and-activity-based-branching">Accumulated Failure Count and Activity-based Branching</h3>
<p>The second new feature of Gecode that we explore here is the <em>Accumulated Failure Count</em> and the <em>Activity-based</em> branching strategies.</p>

<p>While solving any CP model, the strategy used to select the next variable to branch over is very important. The <em>Accumulated Failure Count</em> strategy stores the cumulative number of failures for each variable (for details see Section 8.5 in <a href="http://www.gecode.org/doc-latest/MPG.pdf">MPG</a>). The <em>Activity-based</em> search does something similar, but instead of counting failures, measures the activity of each variable.
In a sense, these two strategies try to <em>learn</em> from failures and activities as they occur during the search process. </p>

<p>These two branching strategies are more effective when combined with <em>Restart Based Search</em>: the solver performs the search with increasing cutoff values on the number of failures. Gecode offers several optional strategies to improve the cutoff. In our tests, we have used a geometric cutoff sequence (Section 9.4 in <a href="http://www.gecode.org/doc-latest/MPG.pdf">MPG</a>).</p>

<blockquote>
  <p>How effective are the <strong>Accumulated Failure Count</strong> and the <strong>Activity-based</strong> strategies for Graph Coloring when combined with <strong>Restart Based Search</strong>?</p>
</blockquote>

<p>The second plot below shows a comparison of 3 versions of GeCol, with 3 different branching strategies:</p>

<ul>
  <li>(A) Select the variable with smallest domain size</li>
  <li>(B) Select the variable with largest Activity Cumulated value</li>
  <li>(C) Select the variable with largest Accumulated Failure Count (AFC) value</li>
</ul>

<p>The last strategy is tremendously efficient: it dominates the other two strategies, and it is able to solve more of the 60% of the considered instances within the timeout of 300 seconds.</p>

<p><img class="center" src="../../../../../../images/Ecdf2.png" /></p>

<p>However, it is possible to do still slightly better. Likely, at the begging of the search phase, several variables have the same value of AFC. Therefore, it is possible to improve the branching strategy by breaking ties: we can divide the ACT or the AFC value of a variable by the its domain size. The next plot shows the results with these other branching strategies:</p>

<ul>
  <li>(A) Select the variable with largest ratio of variable degree vs. domain size</li>
  <li>(B) Select the variable with largest ratio of Activity Cumulated value vs. domain size</li>
  <li>(C) Select the variable with largest ratio of Accumulated Failure Count vs. domain size</li>
</ul>

<p><img class="center" src="../../../../../../images/Ecdf3.png" /></p>

<h2 id="conclusions">Conclusions</h2>
<p>The new features of Gecode are very interesting and offer plenty of options.
The LDBS is very general, and it could be easily applied to several other combinatorial optimization problems.
Also the new branching strategies gives important enhancements, above all when combined with restart based search.</p>

<blockquote>
  <p>”…with great power there must also come – great responsibility!” (Uncle Ben, The Amazing Spider-Man, n.660, Marvel Comics) </p>
</blockquote>

<p>As a drawback, it is becoming harder and harder to find the best parameter configuration for solvers as Gecode (but this is true also for other type of solvers, e.g. Gurobi and Cplex).</p>

<p>Can you find or suggest a better parameter configuration for GeCol?</p>

<h2 id="references">References</h2>
<ol>
  <li>
    <p>S. Gualandi and F. Malucelli.
<span class="title">Exact Solution of Graph Coloring Problems via Constraint Programming and Column Generation</span>.
<span class="journal">INFORMS Journal on Computing</span>. Winter 2012 vol. 24(1), pp.81-100. 
<a href="http://joc.journal.informs.org/content/24/1/81.short">[pdf]</a>
<a href="http://www.optimization-online.org/DB_FILE/2010/03/2568.pdf">[preprint]</a></p>
  </li>
  <li>
    <p>C. Mears, M.G. de la Banda, B. Demoen, M. Wallace.
<span class="title">Lightweight dynamic symmetry breaking</span>.
<span class="journal">In Eighth International Workshop on Symmetry in Constraint Satisfaction Problems,
SymCon’08, 2008.</span> 
<a href="http://www.aloul.net/symcon/Mears2-Symcon08.pdf">[pdf]</a></p>
  </li>
  <li>
    <p>A Mehrotra, MA Trick.
<span class="title">A column generation approach for graph coloring</span>.
<span class="journal">INFORMS Journal on Computing</span>. Fall 1996 vol. 8(4), pp.344-354. 
<a href="http://joc.journal.informs.org/content/8/4/344.short ">[pdf]</a></p>
  </li>
  <li>
    <p>S. Held, W. Cook, E.C. Sewell.
<span class="title">Maximum-weight stable sets and safe lower bounds for graph coloring</span>.
<span class="journal">Mathematical Programming Computation</span>. December 2012, Volume 4, Issue 4, pp 363-381.
<a href="http://link.springer.com/content/pdf/10.1007%2Fs12532-012-0042-3.pdf">[pdf]</a></p>
  </li>
  <li>
    <p>Patric R.J. Ostergard.
<span class="title">A fast algorithm for the maximum clique problem</span>.
<span class="journal">Discrete Applied Mathematics</span>, 
vol. 120(1-3), pp. 197–207, 2002
<a href="http://citeseerx.ist.psu.edu/viewdoc/similar?doi=10.1.1.28.7666&amp;type=cc">[pdf]</a>
</p>
  </li>
</ol>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/03/22/backtrack-programming-in-c/">Backtrack Programming in C</a></h1>
    
    
      <p class="meta">
        








  



  
<time datetime="2013-03-22T12:45:00+01:00" pubdate data-updated="true">Mar 22<span>nd</span>, 2013</time>
        
         | <a href="/blog/2013/03/22/backtrack-programming-in-c/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><style type="text/css">
.title { color: #07235F; }
.journal { font-style: italic; }
</style>

<p>Recently, I have discovered a nice tiny library (1 file!) that supports <a href="http://en.wikipedia.org/wiki/Backtracking">Backtrack Programming</a> in <strong>standard C</strong>.
The library is called <a href="http://www.akira.ruc.dk/~keld/research/CBACK/">CBack</a> and 
is developed by <a href="http://www.akira.ruc.dk/~keld/">Keld Helsgaun</a>, who is known in the Operations Research 
and Computer Science communities for his efficient implementation of the 
Lin-Kernighan heuristics for the <a href="http://www.akira.ruc.dk/~keld/research/LKH/">Travelling Salesman Problem</a>.</p>

<p><strong>CBack</strong> offers basically two functions that are described in [1] as follows:</p>

<ol>
  <li><strong><code>Choice(N)</code></strong>: “<em>is used when a choice is to be made among a number of alternatives, where <strong>N</strong> is a positive integer denoting the number of alternatives</em>”.</li>
  <li><strong><code>Backtrack()</code></strong>: “<em>causes the program to backtrack, that is to say, return to the most recent call of Choice, which has not yet returned all its values</em>”.</li>
</ol>

<p>With these two functions is pretty simple to develop exact enumeration algorithms.
The <strong>CBack</strong> library comes with several examples, such as algorithms for the <a href="http://en.wikipedia.org/wiki/Eight_queens_puzzle">N-queens</a> problem and the <a href="http://en.wikipedia.org/wiki/15_puzzle">15-puzzle</a>.
Below, I will show you how to use <strong>CBack</strong> to implement a simple algorithm that finds a <a href="http://en.wikipedia.org/wiki/Clique_problem">Maximum Clique</a> in an undirected graph.</p>

<p>As usual, the source code used to write this post is publicly available on
<a href="https://github.com/stegua/MyBlogEntries/tree/master/Backtracking">my GitHub repository</a>.</p>

<h2 id="basic-use-of-cback">Basic use of CBack</h2>
<p>The <strong>CBack</strong> documentation shows as first example the following code snippet:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Example</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="c++"><span class="line"><span></span><span class="kt">int</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">;</span>
</span><span class="line"><span class="n">i</span> <span class="o">=</span> <span class="n">Choice</span><span class="p">(</span><span class="mi">3</span><span class="p">);</span>
</span><span class="line"><span class="n">j</span> <span class="o">=</span> <span class="n">Choice</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span>
</span><span class="line"><span class="n">printf</span><span class="p">(</span><span class="s">&quot;i = %d, j = %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">);</span>
</span><span class="line"><span class="n">Backtrack</span><span class="p">();</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The output produced by the snippet is:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Output</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="c++"><span class="line"><span></span><span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span>
</span><span class="line"><span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">2</span>
</span><span class="line"><span class="n">i</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span>
</span><span class="line"><span class="n">i</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">2</span>
</span><span class="line"><span class="n">i</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span>
</span><span class="line"><span class="n">i</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">2</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>If you are familiar with backtrack programming (e.g., <a href="http://en.wikipedia.org/wiki/Prolog">Prolog</a>), you should not be surprised by the output, and you can jump to the next section. Otherwise, 
the Figure below sketches the program execution. </p>

<p><img src="http://stegua.github.io/images/backtrack.png" /></p>

<p>When the program executes the <code>Choice(N=3)</code> statement, that is the first call to the first choice (line 2), value 1 is assigned to variable <code>i</code>. Behind the scene, the <em>Choice</em> function stores the current execution state of the program in its own stack,
and records the next possible choices (i.e. the other possible program branches),
that are values <code>2</code> and <code>3</code>. Next, the second <code>Choice(N=2)</code> assigns value 1 to <code>j</code> (line 3),
and again the state of the program is stored for later use. Then, the <code>printf</code> outputs <code>i = 1 , j = 1</code> (line 4 and first line of output). Now, it is time to <em>backtrack</em> (line 5). </p>

<p>What is happening here?</p>

<p>Look again at the figure above: When the <code>Backtrack()</code> function is invoked, the algorithm <em>backtracks</em> and continues the execution
from the most recent <strong>Choice</strong> stored in its stack, i.e. it assigns to variable <code>j</code> value 2, and <code>printf</code> outputs <code>i = 1, j = 2</code>. Later, the <code>Backtrack()</code> is invoked again, and this time the algorithm backtracks until the previous possible choice that corresponds to the assignment of value 2 to variable <code>i</code>, and it executes <code>i = 2</code>. Once the second choice for variable <code>i</code> is performed, there are again two possible choices for variable <code>j</code>, since the program has backtracked to a point that precedes that statement. Thus, the program executes <code>j = 1</code>, and <code>printf</code> outputs <code>i = 2, j = 1</code>. At this point, the program <em>backtracks</em> again, and consider the next possible choice, <code>j = 2</code>. This is repeated until all possible choices for <code>Choice(3)</code> and <code>Choice(2)</code> are exhausted, yielding the 6 possible combinations of <code>i</code> and <code>j</code> that the problem gave as output.</p>

<p>Indeed, during the execution, the program has implicitly visited in a depth-first manner the <em>search tree</em> of the previous figure.
CBack supports also different search strategy, such as <em>best first</em>, but I will not cover that topic here.</p>

<p>In order to store and restore the program execution state (well, more precisely the <em>calling environment</em>), <code>Choice(N)</code> and <code>Backtrack</code> use two <strong>threatening</strong> C standard functions, <code>setjmp</code> and <code>longjmp</code>. 
For the details of their use in CBack, see [1].</p>

<h2 id="a-basic-maximum-clique-algorithm">A Basic Maximum Clique Algorithm</h2>
<p>The reason why I like this library, apart from remembering me the time I was programming with <a href="http://www.mozart-oz.org/">Mozart</a>, is that it permits to implement quickly exact algorithms based on enumeration. While enumeration is usually disregarded as <em>inefficient</em> (“<em>ehi, it is just brute force</em>!”), it is still one of the best method to solve small instances of almost any combinatorial optimization problem. In addition, many sophisticated exact algorithms use plain enumeration as a subroutine, when during the search process the size of the problem becomes small enough.</p>

<p>Consider now the <strong>Maximum Clique Problem</strong>: Given an undirected graph <script type="math/tex">G=(V,E)</script>, the problem is to find the largest complete subgraph of <script type="math/tex">G</script>. More formally, you look for the largest subset <script type="math/tex">C</script> of the vertex set <script type="math/tex">V</script> such that for any pair of nodes <script type="math/tex">{i,j}</script> in <script type="math/tex">C \times C</script> there exists an arc <script type="math/tex">{i,j} \in E</script>.  </p>

<p>The well-known branch-and-bound algorithm of Carraghan and Pardalos [2] is based on enumeration. The implementation of Applegate and Johnson, called <a href="ftp://dimacs.rutgers.edu/pub/dsj/clique/dfmax.c">dfmax.c</a>, is a very efficient implementation of that algorithm. Next, I show a basic implementation of the same algorithm that uses <strong>CBack</strong> for backtracking.</p>

<p>The Carraghan and Pardalos algorithm uses three sets: the current clique <script type="math/tex">C</script>, the largest clique found so far <script type="math/tex">C^*</script>, and the set of candidate vertices <script type="math/tex">P</script>. The pseudo code of the algorithm is as follows (as described in [3]):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Basic Maximum Clique Algorithm</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span></span><span class="n">function</span> <span class="nf">findClique</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>
</span><span class="line">   <span class="k">if</span> <span class="o">|</span><span class="n">C</span><span class="o">|</span> <span class="o">&gt;</span> <span class="o">|</span><span class="n">C</span><span class="o">*|</span> <span class="n">then</span> <span class="n">C</span><span class="o">*</span> <span class="o">&lt;-</span> <span class="n">C</span>  <span class="c1">// store the best clique</span>
</span><span class="line">   <span class="k">if</span> <span class="o">|</span><span class="n">C</span><span class="o">|</span> <span class="o">+</span> <span class="o">|</span><span class="n">P</span><span class="o">|</span> <span class="o">&gt;</span> <span class="o">|</span><span class="n">C</span><span class="o">*|</span> <span class="n">then</span>
</span><span class="line">      <span class="k">for</span> <span class="n">all</span> <span class="n">v</span> <span class="n">in</span> <span class="n">P</span> <span class="c1">// the order does matter </span>
</span><span class="line">         <span class="n">P</span> <span class="o">&lt;-</span> <span class="n">P</span> <span class="err">\</span> <span class="p">{</span><span class="n">v</span><span class="p">}</span>
</span><span class="line">         <span class="n">C</span><span class="err">&#39;</span> <span class="o">&lt;-</span> <span class="n">C</span> <span class="n">u</span> <span class="p">{</span><span class="n">v</span><span class="p">}</span>
</span><span class="line">         <span class="n">P</span><span class="err">&#39;</span> <span class="o">&lt;-</span> <span class="n">P</span>  <span class="err">\</span><span class="n">intersect</span> <span class="n">N</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>  <span class="c1">// neighbors of p</span>
</span><span class="line">         <span class="n">findClique</span><span class="p">(</span><span class="n">C</span><span class="err">&#39;</span><span class="p">,</span> <span class="n">P</span><span class="err">&#39;</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">function</span> <span class="n">main</span><span class="p">()</span>
</span><span class="line">   <span class="n">C</span><span class="o">*</span> <span class="o">&lt;-</span> <span class="p">{}</span>  <span class="c1">// empty set, C* global variable</span>
</span><span class="line">   <span class="n">findClique</span><span class="p">({},</span><span class="n">V</span><span class="p">)</span>
</span><span class="line">   <span class="k">return</span> <span class="n">C</span><span class="o">*</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>As you can see, the backtracking is here described in terms of a recursive function. However, using CBack, we can implement the same algorithm without using recursion.</p>

<h2 id="maximum-clique-with-cback">Maximum Clique with CBack</h2>
<p>We use an array <code>S</code> of <script type="math/tex">n</script> integers, one for each vertex of <script type="math/tex">V</script>.
If <code>S[v]=0</code>, then vertex <script type="math/tex">i</script> belongs to the candidate set <script type="math/tex">P</script>; if <code>S[v]=1</code>, then vertex <script type="math/tex">i</script> is in <script type="math/tex">C</script>; if <code>S[v]=2</code>, then vertex <script type="math/tex">i</script> cannot be neither in <script type="math/tex">P</script> nor in <script type="math/tex">C</script>. The variable <code>s</code> stores the size of current clique.</p>

<p>Let me show you directly the C code:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Max Clique via Branch-and-Bound</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
</pre></td><td class="code"><pre><code class="c++"><span class="line"><span></span><span class="k">for</span> <span class="p">(</span><span class="n">v</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">v</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">v</span><span class="o">++</span> <span class="p">)</span> <span class="p">{</span>
</span><span class="line">   <span class="c1">/// If the current clique cannot be extended to a clique</span>
</span><span class="line">   <span class="c1">/// larger than C*, where LB=|C*|, then backtrack</span>
</span><span class="line">   <span class="k">if</span> <span class="p">(</span> <span class="n">s</span> <span class="o">+</span> <span class="n">P</span> <span class="o">&lt;=</span> <span class="n">LB</span> <span class="p">)</span>
</span><span class="line">      <span class="n">Backtrack</span><span class="p">();</span>
</span><span class="line">   <span class="k">if</span> <span class="p">(</span> <span class="n">S</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">2</span> <span class="p">)</span> <span class="p">{</span>  <span class="c1">/// Skip removed vertices  </span>
</span><span class="line">      <span class="c1">/// Choice: Either v is in C (S[v]=1) or is not (S[v]=2)</span>
</span><span class="line">      <span class="n">S</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="n">Choice</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span>
</span><span class="line">      <span class="k">if</span> <span class="p">(</span> <span class="n">S</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span> <span class="p">)</span> <span class="p">{</span> <span class="c1">/// P &lt;- P \ {v} </span>
</span><span class="line">         <span class="n">P</span><span class="o">--</span><span class="p">;</span>  <span class="c1">/// Decrease the size of the candidate set </span>
</span><span class="line">      <span class="p">}</span> <span class="k">else</span> <span class="p">{</span> <span class="c1">/// S[v]=1: C &lt;- C u {v}</span>
</span><span class="line">         <span class="n">s</span><span class="o">++</span><span class="p">;</span>   <span class="c1">/// Update current clique size </span>
</span><span class="line">         <span class="k">if</span> <span class="p">(</span> <span class="n">s</span> <span class="o">&gt;</span> <span class="n">LB</span> <span class="p">)</span> <span class="p">{</span>
</span><span class="line">            <span class="n">LB</span> <span class="o">=</span> <span class="n">s</span><span class="p">;</span>  <span class="c1">/// Store the new best clique</span>
</span><span class="line">            <span class="k">for</span> <span class="p">(</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">w</span> <span class="o">&lt;=</span> <span class="n">v</span><span class="p">;</span> <span class="n">w</span><span class="o">++</span> <span class="p">)</span>
</span><span class="line">               <span class="n">C</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">S</span><span class="p">[</span><span class="n">w</span><span class="p">];</span>
</span><span class="line">         <span class="p">}</span>
</span><span class="line">         <span class="c1">/// Restrict the candidate set </span>
</span><span class="line">         <span class="k">for</span> <span class="p">(</span> <span class="n">w</span> <span class="o">=</span> <span class="n">V</span><span class="p">[</span><span class="n">v</span><span class="o">+</span><span class="mi">1</span><span class="p">];</span> <span class="n">w</span> <span class="o">&gt;</span> <span class="n">V</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="p">;</span> <span class="n">w</span><span class="o">--</span> <span class="p">)</span>
</span><span class="line">            <span class="k">if</span> <span class="p">(</span> <span class="n">S</span><span class="p">[</span><span class="n">E</span><span class="p">[</span><span class="n">w</span><span class="p">]]</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
</span><span class="line">               <span class="n">S</span><span class="p">[</span><span class="n">E</span><span class="p">[</span><span class="n">w</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
</span><span class="line">               <span class="n">P</span><span class="o">--</span><span class="p">;</span> <span class="c1">/// Decrease the size of the candidate set </span>
</span><span class="line">            <span class="p">}</span>
</span><span class="line">      <span class="p">}</span>
</span><span class="line">   <span class="p">}</span>
</span><span class="line"><span class="p">}</span>
</span><span class="line"><span class="n">Backtrack</span><span class="p">();</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Well, I like this code pretty much, despite being a “<em>plain old</em>” C program.
The algorithm and code can be improved in several ways (ordering the vertices, improving the pruning, using upper bounds from heuristic vertex coloring, using induced degree as in [2]), but still, the main loop and the backtrack machinery is all there, in a few lines of code!</p>

<p>Maybe you wonder about the efficiency of this code, but at the moment I have not a precise answer. For sure, the ordering of the vertices is crucial, and can make a huge difference on solving the <a href="http://iridia.ulb.ac.be/~fmascia/maximum_clique/DIMACS-benchmark">max-clique DIMACS instances</a>. I have used CBack to implement my own version of the Ostengard’s max-clique algorithm [4], but my implementation is somehow slower. I suspect that the difference is due to data structure used to store the graph (Ostengard’s implementation relies on bitsets), but not in the way the backtracking is achieved. Although, to answer to such question could be a subject of another post.</p>

<p>In conclusion, if you need to implement an exact enumerative algorithm, <a href="http://www.akira.ruc.dk/~keld/research/CBACK/">CBack</a> could be an option to consider.</p>

<h3 id="references">References</h3>

<ol>
  <li>
    <p>Keld Helsgaun. 
<span class="title">CBack: A Simple Tool for Backtrack Programming in C</span>. 
<span class="journal">Software: Practice and Experience</span>, 
vol. 25(8), pp. 905-934, 2006. 
<a href="http://dx.doi.org/10.1002/spe.4380250805">[doi]</a>
</p>
  </li>
  <li>
    <p>Carraghan and Pardalos. 
<span class="title">An exact algorithm for the maximum clique problem</span>. 
<span class="journal">Operations Research Letters</span>, 
vol. 9(6), pp. 375-382, 1990, 
<a href="http://www.dcs.gla.ac.uk/~pat/jchoco/clique/papersClique/carraghanPardalos90.pdf">[pdf]</a>
</p>
  </li>
  <li>
    <p>Torsten Fahle. 
<span class="title">Simple and Fast: Improving a Branch-and-Bound Algorithm</span>. 
In Proc <span class="journal">ESA 2002</span>, LNCS 2461, pp. 485-498.
<a href="http://dx.doi.org/10.1007/3-540-45749-6_44">[doi]</a>
</p>
  </li>
  <li>
    <p>Patric R.J. Ostergard.
<span class="title">A fast algorithm for the maximum clique problem</span>.
<span class="journal">Discrete Applied Mathematics</span>, 
vol. 120(1-3), pp. 197–207, 2002
<a href="http://citeseerx.ist.psu.edu/viewdoc/similar?doi=10.1.1.28.7666&amp;type=cc">[pdf]</a>
</p>
  </li>
</ol>

</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>About Me</h1>
  <p>The views expressed on this blog are mine and do not necessarily reflect the views of my employers.</p>
  <nav>
  <div><a href="http://matematica.unipv.it/gualandi/">My Academic Home Page</a></div>
  <div><a href="http://matematica.unipv.it/gualandi/research/">My Publications</a></div>
  </nav>
  </p>
  <p>
  I do not accept any advertisement. 
  However, you can offer me <a href="http://paypal.me/stegua/2.10">coffee and brioche</a> or <a href="http://paypal.me/stegua/7.00">pizza capricciosa</a> through paypal.
  </p>
</section>

<section>
 <h2>Latest Tweets</h2>
<a class="twitter-timeline" href="https://twitter.com/famo2spaghi" data-widget-id="303485589863407617">Tweets by @famo2spaghi</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
<script type="text/javascript">
   $.domReady(function(){
         getTwitterFeed("famo2spaghi", 3, true);
         });
</script>
<script src="/javascripts/twitter.js" type="text/javascript"> </script>

<a href="http://twitter.com/famo2spaghi" class="twitter-follow-button" data-show-count="true">Follow @famo2spaghi</a>

</section>


<section class="googleplus">
  <h1>
    <a href="https://plus.google.com/+StefanoGualandi?rel=author">
      <img src="http://www.google.com/images/icons/ui/gprofile_button-32.png" width="32" height="32">
      My Google+ profile
    </a>
  </h1>
</section>


<section>
  <h2>Recent Posts</h2>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2018/12/31/wasserstein-distances-an-operations-research-perspective/">An informal and biased Tutorial on Kantorovich-Wasserstein distances</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/01/24/exercise-in-python-remove-blanks-from-strings/">Exercise in Python: remove blanks from strings</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/07/04/column-enumeration/">Graph Coloring: Column Generation or Column Enumeration?</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/09/27/big-data-and-convex-optimization/">Big Data and Convex Optimization</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/03/19/the-impact-of-preprocessing/">The Impact of Preprocessing on the MIPLIB2003</a>
      </li>
    
  </ul>
</section>

<section>
  <h2>GitHub Repos</h2>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/stegua">@stegua</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'stegua',
            count: 2,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section>
  <h1>Blogroll</h1>
  <!-- IMPORTANT: Do not change the below ID as it will affect the functioning of the plugin-->
    <ul id="blogroll-list"><li><a href='http://bartoszmilewski.com/' feedurl='http://bartoszmilewski.com/feed/' title = 'Concurrency, C++, Haskell'>Bartosz Milewski&#8217;s Programming Cafe</a></li><li><a href='http://cp-is-fun.blogspot.fr/' feedurl='' title = 'Constraint Programming is fun'>CP is fun</a></li><li><a href='http://bob4er.blogspot.com/' feedurl='http://bob4er.blogspot.com/feeds/posts/default' title = ''>disORiented</a></li><li><a href='http://erlingdandersen.blogspot.it/' feedurl='http://erlingdandersen.blogspot.com/feeds/posts/default' title = 'This blog is about my work at MOSEK ApS where I am the CEO, a computer programmer and tea maker'>Erling&#8217;s blog</a></li><li><a href='http://farkasdilemma.wordpress.com' feedurl='http://farkasdilemma.wordpress.com/feed' title = 'Austin Buchanan's Blog'>Farkas&#8217; Dilemma</a></li><li><a href='https://www.ibm.com/developerworks/mydeveloperworks/blogs/jfp/?lang=en' feedurl='https://www.ibm.com/developerworks/mydeveloperworks/blogs/roller-ui/rendering/feed/jfp/entries/atom?lang=en' title = 'Making Mathematical Optimization Pervasive'>IT Best Kept Secret Is Optimization</a></li><li><a href='http://mat.gsia.cmu.edu/blog/' feedurl='http://feeds.feedburner.com/MichaelTricksORB' title = 'Thoughts on the world of operations research'>Michael Trick’s Operations Research Blog</a></li><li><a href='http://www.hakank.org/constraint_programming_blog/' feedurl='http://www.hakank.org/constraint_programming_blog/atom.xml' title = 'This is my blog about constraint programming and related paradigms'>My Constraint Programming Blog</a></li><li><a href='http://nathanbrixius.wordpress.com/' feedurl='http://nathanbrixius.wordpress.com/feed/' title = 'Optimization, analytics, software'>Nathan Brixius</a></li><li><a href='http://zverovich.net/' feedurl='http://zverovich.net/atom.xml' title = 'Victor Zverovich'>Notes of a humble developer</a></li><li><a href='http://orbythebeach.wordpress.com/' feedurl='http://feeds.feedburner.com/OrByTheBeach' title = 'Operations Research, Computers, Education, and South Florida'>O.R. by the Beach</a></li><li><a href='http://optimizationzen.com/' feedurl='http://feeds.feedburner.com/optimizationzen' title = 'The Art of Decision Making'>Optimization Zen</a></li><li><a href='http://orinanobworld.blogspot.it/' feedurl='http://orinanobworld.blogspot.com/feeds/posts/default' title = 'A mix of operations research items and software tricks that I'll probably forget if I don't write them down somewhere'>OR in an OB World</a></li><li><a href='http://punkrockor.wordpress.com/' feedurl='http://punkrockor.wordpress.com/feed/' title = '~*~ peace, love, and operations research ~*~'>Punk Rock Operations Research</a></li><li><a href='http://spokutta.wordpress.com/' feedurl='http://spokutta.wordpress.com/feed/' title = 'Mathematics and related topics'>Sebastian Pokutta&#8217;s blog</a></li><li><a href='http://thiagoserra.com' feedurl='http://thiagoserra.com/feed' title = ''>Tatu-Search Optimization</a></li><li><a href='http://org.mie.utoronto.ca/blog/' feedurl='' title = 'An Operations Research blog from the University of Toronto'>The OR Café</a></li><li><a href='http://www.thequestforoptimality.com/' feedurl='http://www.thequestforoptimality.com/feed/' title = 'OR made fun and practical'>The Quest for Optimality</a></li></ul>
    
    <script type="text/javascript">
      $(document).ready(function(){
        updateFeeds(true);
      });
    </script>
    <script src="/javascripts/tinysort-min.js"></script>
    <script src="/javascripts/blogroll.js"></script>
    
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2019 - Stefano Gualandi -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'famo2spaghi';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
